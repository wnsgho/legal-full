from difflib import get_close_matches
from logging import Logger
import faiss
from neo4j import GraphDatabase
import time
import nltk
from nltk.corpus import stopwords
import re
try:
    stopwords.words('english')
except LookupError:
    nltk.download('stopwords', quiet=True)
from graphdatascience import GraphDataScience
from atlas_rag.llm_generator.llm_generator import LLMGenerator
from atlas_rag.vectorstore.embedding_model import BaseEmbeddingModel
import string
from atlas_rag.retriever.lkg_retriever.base import BaseLargeKGRetriever
from atlas_rag.retriever.lkg_retriever.lkgr import LargeKGRetriever


class EnhancedLargeKGRetriever(LargeKGRetriever):
    """
    ì¡°í•­ ê²€ìƒ‰ ê¸°ëŠ¥ê³¼ ì—°ê²°ëœ ë…¸ë“œ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ í–¥ìƒëœ LKG ë¦¬íŠ¸ë¼ì´ë²„
    """
    
    def __init__(self, keyword: str, neo4j_driver: GraphDatabase, 
                llm_generator: LLMGenerator, sentence_encoder: BaseEmbeddingModel, 
                node_index: faiss.Index, passage_index: faiss.Index, 
                topN: int = 5,
                number_of_source_nodes_per_ner: int = 10,
                sampling_area: int = 250, logger: Logger = None, **kwargs):
        
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(keyword, neo4j_driver, llm_generator, sentence_encoder, 
                        node_index, passage_index, topN, number_of_source_nodes_per_ner, 
                        sampling_area, logger, **kwargs)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ì„¤ì •
        print(f"ğŸ” EnhancedLargeKGRetriever kwargs: {kwargs}", flush=True)
        print(f"ğŸ” database í‚¤ ì¡´ì¬: {'database' in kwargs}", flush=True)
        print(f"ğŸ” database ê°’: {kwargs.get('database', 'NOT_FOUND')}", flush=True)
        self.database_name = kwargs.get('database', 'neo4j')
        print(f"ğŸ” self.database_name ì„¤ì •: {self.database_name}", flush=True)
        
        # ì¡°í•­ ê²€ìƒ‰ ê´€ë ¨ ì„¤ì •
        self.clause_patterns = [
            r'ì œ\d+ì¡°',
            r'\d+ì¡°',
            r'ì¡°í•­\s*\d+',
            r'ì œ\d+ì¡°\s*\d+í•­',
            r'\d+ì¡°\s*\d+í•­',
            r'ë¹„ë°€ìœ ì§€',
            r'ê³„ì•½í•´ì§€',
            r'ì†í•´ë°°ìƒ',

        ]
        
        # ì—°ê²°ëœ ë…¸ë“œ ê²€ìƒ‰ ì„¤ì •
        self.connected_nodes_limit = 100  # ì˜ë¯¸ì /ì»¨ì…‰ ê²€ìƒ‰ ê²°ê³¼ì˜ ì—°ê²°ëœ ë…¸ë“œ ìˆ˜ ì¦ê°€
        self.max_hops = 7  # ìµœëŒ€ 7í™‰ê¹Œì§€ ê²€ìƒ‰
        
    def is_clause_question(self, question):
        """
        ì§ˆë¬¸ì´ ì¡°í•­ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
        """
        if self.verbose:
            self.logger.info(f"ì¡°í•­ ì§ˆë¬¸ íŒë‹¨ - ì§ˆë¬¸: '{question}'")
        
        for i, pattern in enumerate(self.clause_patterns):
            if re.search(pattern, question):
                if self.verbose:
                    self.logger.info(f"ì¡°í•­ íŒ¨í„´ ë§¤ì¹­ ì„±ê³µ: íŒ¨í„´ {i+1} '{pattern}'")
                return True
        
        if self.verbose:
            self.logger.info("ì¡°í•­ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ - ëª¨ë“  íŒ¨í„´ í™•ì¸ ì™„ë£Œ")
        return False
    
    def _extract_keywords_from_query(self, query):
        """
        ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ)
        """
        import re
        
        # ë¶ˆìš©ì–´ ì œê±° (ì§ˆë¬¸ì—ì„œ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œ)
        stop_words = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì˜', 'ë„', 'ë§Œ', 'ê¹Œì§€', 'ë¶€í„°', 'í•œ', 'í• ', 'í•œë‹¤ë©´', 'ìˆ˜', 'ìˆë‚˜ìš”', 'ì¸ê°€ìš”', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ì™œ', 'ì–´ë–¤']
        
        # ì§ˆë¬¸ì„ ë‹¨ì–´ë¡œ ë¶„ë¦¬ (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ)
        words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', query)
        
        # ë¶ˆìš©ì–´ ì œê±°í•˜ê³  2ê¸€ì ì´ìƒì¸ ë‹¨ì–´ë§Œ ì„ íƒ
        keywords = []
        for word in words:
            if len(word) >= 2 and word not in stop_words:
                keywords.append(word)
        
        return keywords
    
    def _search_by_keywords(self, keywords, topN=10):
        """
        í‚¤ì›Œë“œë¡œ Neo4jì—ì„œ ì§ì ‘ ê²€ìƒ‰
        """
        if not keywords:
            return []
            
        try:
            with self.neo4j_driver.session(database=self.database_name) as session:
                all_results = []
                
                for keyword in keywords:
                    # Text ë…¸ë“œì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                    query = """
                    MATCH (t:Text)
                    WHERE t.text CONTAINS $keyword
                    RETURN t.numeric_id as textId, t.text as text,
                           'keyword_match' as match_type,
                           size(t.text) as text_length
                    ORDER BY text_length DESC
                    LIMIT $topN
                    """
                    
                    result = session.run(query, keyword=keyword, topN=topN)
                    keyword_results = [dict(record) for record in result]
                    all_results.extend(keyword_results)
                
                # ì¤‘ë³µ ì œê±°
                seen_ids = set()
                unique_results = []
                for result in all_results:
                    if result['textId'] not in seen_ids:
                        seen_ids.add(result['textId'])
                        unique_results.append(result)
                
                if self.verbose:
                    self.logger.info(f"í‚¤ì›Œë“œ ê²€ìƒ‰: ì´ {len(all_results)}ê°œ ê²°ê³¼, ì¤‘ë³µ ì œê±° í›„ {len(unique_results)}ê°œ")
                
                return unique_results[:topN]
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def search_clause_directly(self, question, topN=10):
        """
        ì¡°í•­ ì§ˆë¬¸ì— ëŒ€í•´ ì§ì ‘ Neo4jì—ì„œ ê²€ìƒ‰ (ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°)
        """
        try:
            with self.neo4j_driver.session(database=self.database_name) as session:
                all_results = []
                
                # 1. ì¡°í•­ ë²ˆí˜¸ ì¶”ì¶œí•˜ì—¬ ê²€ìƒ‰
                clause_matches = re.findall(r'ì œ?(\d+)ì¡°', question)
                if clause_matches:
                    for clause_num in clause_matches:
                        clause_number = int(clause_num)
                        results = self._search_by_clause_number(session, clause_number, topN)
                        all_results.extend(results)
                        if self.verbose:
                            self.logger.info(f"ì œ{clause_number}ì¡° ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                
                # 2. ì¡°í•­ ìœ í˜•ìœ¼ë¡œ ê²€ìƒ‰
                clause_type_patterns = {
                    'ë¹„ë°€ìœ ì§€': ['ë¹„ë°€ìœ ì§€', 'ë¹„ë°€ë³´í˜¸'],
                    'ê³„ì•½í•´ì§€': ['ê³„ì•½í•´ì§€', 'í•´ì§€'],
                    'ì†í•´ë°°ìƒ': ['ì†í•´ë°°ìƒ', 'ë°°ìƒ'],
                    'ì§€ì ì¬ì‚°ê¶Œ': ['ì§€ì ì¬ì‚°ê¶Œ', 'ì €ì‘ê¶Œ'],
                    'ìœ ì§€ë³´ìˆ˜': ['ìœ ì§€ë³´ìˆ˜', 'ì§€ì›'],
                    'ëŒ€ê°€': ['ëŒ€ê°€', 'ìš”ê¸ˆ', 'ë¹„ìš©'],
                    'ì±…ì„': ['ì±…ì„', 'ì˜ë¬´'],
                    'íš¨ë ¥': ['íš¨ë ¥', 'ë°œíš¨'],
                    'ë¶„ìŸ': ['ë¶„ìŸ', 'ì†Œì†¡']
                }
                
                for clause_type, keywords in clause_type_patterns.items():
                    if any(keyword in question for keyword in keywords):
                        results = self._search_by_clause_type(session, clause_type, topN)
                        all_results.extend(results)
                        if self.verbose:
                            self.logger.info(f"{clause_type} ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                
                # 3. ì¼ë°˜ì ì¸ ì¡°í•­ ê²€ìƒ‰
                if not all_results:
                    results = self._search_by_general_clause(session, question, topN)
                    all_results.extend(results)
                    if self.verbose:
                        self.logger.info(f"ì¼ë°˜ ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                
                # 4. ì¤‘ë³µ ì œê±° (textId ê¸°ì¤€)
                seen_ids = set()
                unique_results = []
                for result in all_results:
                    if result['textId'] not in seen_ids:
                        seen_ids.add(result['textId'])
                        unique_results.append(result)
                
                if self.verbose:
                    self.logger.info(f"ì´ ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼: {len(unique_results)}ê°œ (ì¤‘ë³µ ì œê±° í›„)")
                
                return unique_results[:topN]
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"ì¡°í•­ ì§ì ‘ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _search_by_clause_number(self, session, clause_number, topN):
        """ì¡°í•­ ë²ˆí˜¸ë¡œ ê²€ìƒ‰"""
        all_results = []
        
        # 1. ì •í™•í•œ ì¡°í•­ ë²ˆí˜¸ ê²€ìƒ‰
        query1 = """
        MATCH (t:Text)
        WHERE t.text CONTAINS $clause_query
        RETURN t.numeric_id as textId, t.text as text, 
               'exact_clause_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        clause_query = f"ì œ{clause_number}ì¡°"
        result1 = session.run(query1, clause_query=clause_query, topN=topN)
        all_results.extend([dict(record) for record in result1])
        
        # 2. ì¡°í•­ ë²ˆí˜¸ë§Œìœ¼ë¡œ ê²€ìƒ‰ (ì œ ì—†ì´)
        query2 = """
        MATCH (t:Text)
        WHERE t.text CONTAINS $clause_query2
        RETURN t.numeric_id as textId, t.text as text, 
               'number_clause_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        clause_query2 = f"{clause_number}ì¡°"
        result2 = session.run(query2, clause_query2=clause_query2, topN=topN)
        all_results.extend([dict(record) for record in result2])
        
        # 3. ì¡°í•­ ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
        query3 = """
        MATCH (t:Text)
        WHERE t.text CONTAINS $clause_title
        RETURN t.numeric_id as textId, t.text as text, 
               'title_clause_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        clause_title = f"ì œ{clause_number}ì¡° ("
        result3 = session.run(query3, clause_title=clause_title, topN=topN)
        all_results.extend([dict(record) for record in result3])
        
        # 4. ì¡°í•­ ë²ˆí˜¸ê°€ í¬í•¨ëœ ëª¨ë“  í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë” ë„“ì€ ë²”ìœ„)
        query4 = """
        MATCH (t:Text)
        WHERE t.text =~ $clause_regex
        RETURN t.numeric_id as textId, t.text as text, 
               'regex_clause_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        clause_regex = f".*ì œ{clause_number}ì¡°.*"
        result4 = session.run(query4, clause_regex=clause_regex, topN=topN)
        all_results.extend([dict(record) for record in result4])
        
        # 5. ì¡°í•­ ë²ˆí˜¸ê°€ ë¬¸ì¥ ì‹œì‘ì— ìˆëŠ” ê²½ìš° ê²€ìƒ‰
        query5 = """
        MATCH (t:Text)
        WHERE t.text STARTS WITH $clause_start
        RETURN t.numeric_id as textId, t.text as text, 
               'start_clause_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        clause_start = f"ì œ{clause_number}ì¡°"
        result5 = session.run(query5, clause_start=clause_start, topN=topN)
        all_results.extend([dict(record) for record in result5])
        
        # ì¤‘ë³µ ì œê±°
        seen_ids = set()
        unique_results = []
        for result in all_results:
            if result['textId'] not in seen_ids:
                seen_ids.add(result['textId'])
                unique_results.append(result)
        
        if self.verbose:
            self.logger.info(f"ì œ{clause_number}ì¡° ê²€ìƒ‰: ì´ {len(all_results)}ê°œ ê²°ê³¼, ì¤‘ë³µ ì œê±° í›„ {len(unique_results)}ê°œ")
        
        return unique_results[:topN]
    
    def _search_by_clause_type(self, session, clause_type, topN):
        """ì¡°í•­ ìœ í˜•ìœ¼ë¡œ ê²€ìƒ‰"""
        query = """
        MATCH (t:Text)
        WHERE t.text CONTAINS $clause_type
        RETURN t.numeric_id as textId, t.text as text,
               'clause_type_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        result = session.run(query, clause_type=clause_type, topN=topN)
        return [dict(record) for record in result]
    
    def _search_by_general_clause(self, session, question, topN):
        """ì¼ë°˜ì ì¸ ì¡°í•­ ê²€ìƒ‰"""
        query = """
        MATCH (t:Text)
        WHERE t.text CONTAINS $question
        RETURN t.numeric_id as textId, t.text as text,
               'general_clause_match' as match_type,
               size(t.text) as text_length
        ORDER BY text_length DESC
        LIMIT $topN
        """
        
        result = session.run(query, question=question, topN=topN)
        return [dict(record) for record in result]
    
    def get_connected_nodes(self, node_ids, limit=None, max_hops=None):
        """
        ì£¼ì–´ì§„ ë…¸ë“œë“¤ì— ì—°ê²°ëœ ë‹¤ë¥¸ ë…¸ë“œë“¤ì„ ìµœëŒ€ 7í™‰ê¹Œì§€ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            node_ids: ì—°ê²°ëœ ë…¸ë“œë¥¼ ì°¾ì„ ê¸°ì¤€ ë…¸ë“œ IDë“¤
            limit: ê°€ì ¸ì˜¬ ì—°ê²°ëœ ë…¸ë“œì˜ ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ê°’: self.connected_nodes_limit)
            max_hops: ìµœëŒ€ í™‰ ìˆ˜ (ê¸°ë³¸ê°’: self.max_hops)
            
        Returns:
            list: ì—°ê²°ëœ ë…¸ë“œë“¤ì˜ ì •ë³´
        """
        if not node_ids:
            return []
            
        if limit is None:
            limit = self.connected_nodes_limit
        if max_hops is None:
            max_hops = self.max_hops
            
        try:
            with self.neo4j_driver.session(database=self.database_name) as session:
                # ìµœëŒ€ 7í™‰ê¹Œì§€ ì—°ê²°ëœ ë…¸ë“œë“¤ì„ ì°¾ëŠ” ì¿¼ë¦¬
                query = """
                UNWIND $node_ids AS node_id
                MATCH path = (n:Node {numeric_id: node_id})-[r:Relation*1..$max_hops]-(connected:Node)
                WHERE connected.numeric_id <> node_id
                WITH connected, 
                     length(path) as hop_count,
                     count(r) as connection_count
                ORDER BY hop_count ASC, connection_count DESC, connected.numeric_id
                LIMIT $limit
                RETURN connected.numeric_id as numeric_id, 
                       connected.name as name,
                       connected.type as type,
                       hop_count,
                       connection_count
                """
                
                result = session.run(query, 
                                   node_ids=node_ids, 
                                   limit=limit, 
                                   max_hops=max_hops)
                connected_nodes = [dict(record) for record in result]
                
                if self.verbose:
                    hop_distribution = {}
                    for node in connected_nodes:
                        hop = node['hop_count']
                        hop_distribution[hop] = hop_distribution.get(hop, 0) + 1
                    self.logger.info(f"ì—°ê²°ëœ ë…¸ë“œ {len(connected_nodes)}ê°œ ë°œê²¬ (í™‰ ë¶„í¬: {hop_distribution})")
                
                return connected_nodes
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"ì—°ê²°ëœ ë…¸ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def get_connected_text_nodes(self, node_ids, limit=None, max_hops=None):
        """
        ì£¼ì–´ì§„ ë…¸ë“œë“¤ì— ì—°ê²°ëœ Text ë…¸ë“œë“¤ì„ ìµœëŒ€ 7í™‰ê¹Œì§€ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        Relation ê´€ê³„ë¥¼ í†µí•´ ê´€ë ¨ ê°œë… ë…¸ë“œë“¤ì„ ì°¾ê³ , ê·¸ ë…¸ë“œë“¤ì´ ê°€ë¦¬í‚¤ëŠ” ë‹¤ë¥¸ Text ë…¸ë“œë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            node_ids: ì—°ê²°ëœ Text ë…¸ë“œë¥¼ ì°¾ì„ ê¸°ì¤€ ë…¸ë“œ IDë“¤
            limit: ê°€ì ¸ì˜¬ ì—°ê²°ëœ Text ë…¸ë“œì˜ ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ê°’: self.connected_nodes_limit)
            max_hops: ìµœëŒ€ í™‰ ìˆ˜ (ê¸°ë³¸ê°’: self.max_hops)
            
        Returns:
            list: ì—°ê²°ëœ Text ë…¸ë“œë“¤ì˜ ì •ë³´
        """
        if not node_ids:
            return []
            
        if limit is None:
            limit = self.connected_nodes_limit
        if max_hops is None:
            max_hops = self.max_hops
            
        try:
            with self.neo4j_driver.session(database=self.database_name) as session:
                # ìµœëŒ€ 7í™‰ê¹Œì§€ ì—°ê²°ëœ Text ë…¸ë“œë“¤ì„ ì°¾ëŠ” ì¿¼ë¦¬
                query = """
                UNWIND $node_ids AS node_id
                MATCH path = (n:Node {numeric_id: node_id})-[r:Relation*1..$max_hops]-(related:Node)
                MATCH (related)-[:Source]->(t:Text)
                WHERE t.numeric_id <> node_id AND related.numeric_id <> node_id
                WITH t, 
                     length(path) as hop_count,
                     count(related) as relation_count
                ORDER BY hop_count ASC, relation_count DESC, size(t.text) DESC
                LIMIT $limit
                RETURN t.numeric_id as textId, 
                       t.text as text,
                       hop_count,
                       relation_count
                """
                
                result = session.run(query, 
                                   node_ids=node_ids, 
                                   limit=limit, 
                                   max_hops=max_hops)
                connected_text_nodes = [dict(record) for record in result]
                
                if self.verbose:
                    hop_distribution = {}
                    for node in connected_text_nodes:
                        hop = node['hop_count']
                        hop_distribution[hop] = hop_distribution.get(hop, 0) + 1
                    self.logger.info(f"ì—°ê²°ëœ Text ë…¸ë“œ {len(connected_text_nodes)}ê°œ ë°œê²¬ (í™‰ ë¶„í¬: {hop_distribution})")
                
                return connected_text_nodes
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"ì—°ê²°ëœ Text ë…¸ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def check_gds_graph(self):
        """
        GDS ê·¸ë˜í”„ê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        """
        try:
            graph = self.gds_driver.graph.get('largekgrag_graph')
            node_count = graph.node_count()
            if self.verbose:
                self.logger.info(f"GDS ê·¸ë˜í”„ í™•ì¸: {node_count}ê°œ ë…¸ë“œ")
            return True
        except Exception as e:
            if self.verbose:
                self.logger.error(f"GDS ê·¸ë˜í”„ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def retrieve_with_clause_search(self, query, topN=5):
        """
        ì¡°í•­ ê²€ìƒ‰ì´ í†µí•©ëœ retrieve ë©”ì„œë“œ
        """
        if self.verbose:
            self.logger.info(f"í–¥ìƒëœ ê²€ìƒ‰ ì‹œì‘: {query}")
        
        # ë³€ìˆ˜ ì´ˆê¸°í™”
        content = []
        context_ids = []
        
        # 0. GDS ê·¸ë˜í”„ í™•ì¸
        if not self.check_gds_graph():
            if self.verbose:
                self.logger.warning("GDS ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¡°í•­ ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # GDS ê·¸ë˜í”„ê°€ ì—†ìœ¼ë©´ ì¡°í•­ ê²€ìƒ‰ë§Œ ì‚¬ìš©
            if self.is_clause_question(query):
                clause_results = self.search_clause_directly(query, topN=topN)
                if clause_results:
                    content = [result['text'] for result in clause_results]
                    context_ids = [result['textId'] for result in clause_results]
                    return content, context_ids
            return [], []
        
        # 1. ì¡°í•­ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        if self.is_clause_question(query):
            if self.verbose:
                self.logger.info("ì¡°í•­ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€ - ì§ì ‘ ì¡°í•­ ê²€ìƒ‰ ì‹œë„")
            
            # ì¡°í•­ ì§ì ‘ ê²€ìƒ‰ (10ê°œë¡œ ì œí•œ)
            clause_results = self.search_clause_directly(query, topN=10)
            if clause_results:
                if self.verbose:
                    self.logger.info(f"ì¡°í•­ ê²€ìƒ‰ìœ¼ë¡œ {len(clause_results)}ê°œ ê²°ê³¼ ë°œê²¬")
                
                # ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                content = [result['text'] for result in clause_results]
                context_ids = [result['textId'] for result in clause_results]
                
                # ì¡°í•­ê³¼ ì—°ê²°ëœ ì¶”ê°€ ë…¸ë“œë“¤ ì°¾ê¸°
                if context_ids:
                    if self.verbose:
                        self.logger.info(f"ì¡°í•­ ê²€ìƒ‰ìœ¼ë¡œ {len(context_ids)}ê°œ Text ë…¸ë“œ ë°œê²¬, ì—°ê²°ëœ ë…¸ë“œ ê²€ìƒ‰ ì‹œì‘")
                    
                    # Text ë…¸ë“œì—ì„œ ì—°ê²°ëœ Nodeë“¤ì„ ì°¾ê¸°
                    connected_nodes = self._get_nodes_from_text_ids(context_ids)
                    if connected_nodes:
                        if self.verbose:
                            self.logger.info(f"ì—°ê²°ëœ ë…¸ë“œ {len(connected_nodes)}ê°œ ë°œê²¬")
                        
                        # ì—°ê²°ëœ ë…¸ë“œë“¤ì˜ Text ë…¸ë“œë“¤ ê°€ì ¸ì˜¤ê¸°
                        additional_texts = self.get_connected_text_nodes(
                            [node['numeric_id'] for node in connected_nodes], 
                            limit=self.connected_nodes_limit
                        )
                        
                        if self.verbose:
                            self.logger.info(f"ì—°ê²°ëœ ë…¸ë“œì—ì„œ {len(additional_texts)}ê°œ ì¶”ê°€ Text ë…¸ë“œ ë°œê²¬")
                        
                        # ì¶”ê°€ í…ìŠ¤íŠ¸ë“¤ì„ ê¸°ì¡´ ê²°ê³¼ì— ì¶”ê°€
                        added_count = 0
                        skipped_count = 0
                        
                        if self.verbose:
                            self.logger.info(f"ê¸°ì¡´ context_ids: {context_ids}")
                            self.logger.info(f"ì¶”ê°€í•  í…ìŠ¤íŠ¸ë“¤: {[t['textId'] for t in additional_texts]}")
                        
                        for additional in additional_texts:
                            if additional['textId'] not in context_ids:
                                content.append(additional['text'])
                                context_ids.append(additional['textId'])
                                added_count += 1
                                if self.verbose:
                                    self.logger.info(f"ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ì¶”ê°€: ID {additional['textId']} - {additional['text'][:50]}...")
                            else:
                                skipped_count += 1
                                if self.verbose:
                                    self.logger.info(f"ì¤‘ë³µìœ¼ë¡œ ìŠ¤í‚µ: ID {additional['textId']} - {additional['text'][:50]}...")
                        
                        if self.verbose:
                            self.logger.info(f"ì—°ê²°ëœ ë…¸ë“œì—ì„œ {added_count}ê°œ í…ìŠ¤íŠ¸ ì¶”ê°€ë¨, {skipped_count}ê°œ ì¤‘ë³µìœ¼ë¡œ ìŠ¤í‚µë¨")
                    else:
                        if self.verbose:
                            self.logger.info("ì—°ê²°ëœ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
                if self.verbose:
                    self.logger.info(f"ìµœì¢… ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼: {len(content)}ê°œ (ì—°ê²°ëœ ë…¸ë“œ í¬í•¨)")
                
                return content[:topN], context_ids[:topN]
            else:
                if self.verbose:
                    self.logger.info("ì¡°í•­ ê²€ìƒ‰ì—ì„œ ê²°ê³¼ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        
        # 2. ì¼ë°˜ LKG ê²€ìƒ‰ ì‹¤í–‰ (GDS PageRank ì‚¬ìš©)
        if self.verbose:
            self.logger.info("ì¼ë°˜ LKG ê²€ìƒ‰ ì‹¤í–‰ (GDS PageRank ì‚¬ìš©)")
        
        try:
            # ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼ë¥¼ personalization_dictë¡œ ì‚¬ìš©
            personalization_dict = {}
            
            # ë””ë²„ê¹…: ì¡°í•­ ì§ˆë¬¸ íŒë‹¨ ê²°ê³¼ í™•ì¸
            is_clause = self.is_clause_question(query)
            if self.verbose:
                self.logger.info(f"ì¡°í•­ ì§ˆë¬¸ íŒë‹¨ ê²°ê³¼: {is_clause}")
            
            # ì¡°í•­ ê²€ìƒ‰ ë˜ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            if is_clause:
                if self.verbose:
                    self.logger.info("ì¡°í•­ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                clause_results = self.search_clause_directly(query, topN=10)
                if self.verbose:
                    self.logger.info(f"ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼: {len(clause_results) if clause_results else 0}ê°œ")
                
                if clause_results:
                    # ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼ì˜ ë…¸ë“œë“¤ì„ personalization_dictì— ì¶”ê°€
                    for result in clause_results:
                        text_id = result['textId']
                        # text_idë¥¼ node_idë¡œ ë³€í™˜í•˜ì—¬ personalization_dictì— ì¶”ê°€
                        if hasattr(self, 'node_list') and text_id.isdigit():
                            faiss_index = int(text_id)
                            if faiss_index < len(self.node_list):
                                node_id = self.node_list[faiss_index]
                                personalization_dict[node_id] = 1.0  # ê°€ì¤‘ì¹˜ 1.0ìœ¼ë¡œ ì„¤ì •
                                if self.verbose:
                                    self.logger.info(f"personalization_dictì— ë…¸ë“œ ì¶”ê°€: {node_id}")
            else:
                # ì¡°í•­ íŒ¨í„´ì´ ì•„ë‹Œ ê²½ìš° í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
                if self.verbose:
                    self.logger.info("ì¡°í•­ íŒ¨í„´ ì•„ë‹˜ - í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                
                # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
                keywords = self._extract_keywords_from_query(query)
                if self.verbose:
                    self.logger.info(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
                
                if keywords:
                    # í‚¤ì›Œë“œë¡œ Neo4jì—ì„œ ì§ì ‘ ê²€ìƒ‰
                    keyword_results = self._search_by_keywords(keywords, topN=10)
                    if self.verbose:
                        self.logger.info(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼: {len(keyword_results) if keyword_results else 0}ê°œ")
                    
                    if keyword_results:
                        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ì˜ ë…¸ë“œë“¤ì„ personalization_dictì— ì¶”ê°€
                        for result in keyword_results:
                            text_id = result['textId']
                            # text_idê°€ ë¬¸ìì—´ì´ë©´ intë¡œ ë³€í™˜, ì´ë¯¸ intë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            if isinstance(text_id, str) and text_id.isdigit():
                                faiss_index = int(text_id)
                            elif isinstance(text_id, int):
                                faiss_index = text_id
                            else:
                                continue  # ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ê±´ë„ˆë›°ê¸°
                            
                            if hasattr(self, 'node_list') and faiss_index < len(self.node_list):
                                node_id = self.node_list[faiss_index]
                                personalization_dict[node_id] = 0.8  # í‚¤ì›Œë“œ ê²€ìƒ‰ì€ ê°€ì¤‘ì¹˜ 0.8
                                if self.verbose:
                                    self.logger.info(f"í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ personalization_dictì— ë…¸ë“œ ì¶”ê°€: {node_id}")
            
            # personalization_dictê°€ ìˆìœ¼ë©´ PageRank ì‚¬ìš©, ì—†ìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰
            if personalization_dict:
                if self.verbose:
                    self.logger.info(f"PageRank personalization_dict ì‚¬ìš©: {len(personalization_dict)}ê°œ ë…¸ë“œ")
                
                # GDS ê·¸ë˜í”„ëŠ” ìˆ«ì IDë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
                # personalization_dictì˜ í‚¤(ì‹¤ì œ ë…¸ë“œ ID)ë¥¼ GDS ë‚´ë¶€ ìˆ«ì IDë¡œ ë³€í™˜
                if self.verbose:
                    self.logger.info("GDS ê·¸ë˜í”„ìš© personalization_dict ì‚¬ìš© (GDS ë‚´ë¶€ ìˆ«ì IDë¡œ ë³€í™˜)")
                
                # node_listë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ì‹œ ID â†’ ìˆ«ì ì¸ë±ìŠ¤ â†’ GDS IDë¡œ ë³€í™˜
                numeric_personalization_dict = {}
                
                # node_listê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
                if self.verbose:
                    self.logger.info(f"node_list í™•ì¸ - hasattr: {hasattr(self, 'node_list')}, ê°’: {getattr(self, 'node_list', None)}")
                    if hasattr(self, 'node_list') and self.node_list:
                        self.logger.info(f"node_list ê¸¸ì´: {len(self.node_list)}")
                        self.logger.info(f"node_list íƒ€ì…: {type(self.node_list)}")
                        self.logger.info(f"node_list ì²« ë²ˆì§¸ ìš”ì†Œ: {self.node_list[0] if self.node_list else 'None'}")
                
                if hasattr(self, 'node_list') and self.node_list:
                    if self.verbose:
                        self.logger.info(f"node_list ì‚¬ìš©í•˜ì—¬ ë³€í™˜ (ê¸¸ì´: {len(self.node_list)})")
                        self.logger.info(f"personalization_dict í‚¤ ê°œìˆ˜: {len(personalization_dict)}")
                        self.logger.info(f"ì²« ë²ˆì§¸ í‚¤ ì˜ˆì‹œ: {list(personalization_dict.keys())[:3]}")
                    
                    for node_id, weight in personalization_dict.items():
                        try:
                            # node_listì—ì„œ í•´ì‹œ IDì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                            if node_id in self.node_list:
                                numeric_index = self.node_list.index(node_id)
                                # GDS ê·¸ë˜í”„ì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë…¸ë“œ ID ê°€ì ¸ì˜¤ê¸°
                                with self.neo4j_driver.session(database=self.database_name) as session:
                                    result = session.run(
                                        "MATCH (n:Node) WHERE n.numeric_id = $numeric_id RETURN id(n) as gds_id", 
                                        numeric_id=numeric_index
                                    )
                                    record = result.single()
                                    if record:
                                        gds_id = record["gds_id"]
                                        numeric_personalization_dict[gds_id] = weight
                                        if self.verbose and len(numeric_personalization_dict) <= 3:
                                            self.logger.info(f"í•´ì‹œ ID {node_id[:20]}... -> ì¸ë±ìŠ¤ {numeric_index} -> GDS ID {gds_id}")
                                    else:
                                        if self.verbose:
                                            self.logger.warning(f"ì¸ë±ìŠ¤ {numeric_index}ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                            else:
                                if self.verbose:
                                    self.logger.warning(f"í•´ì‹œ ID {node_id[:20]}...ê°€ node_listì— ì—†ìŒ")
                        except Exception as e:
                            if self.verbose:
                                self.logger.warning(f"í•´ì‹œ ID ë³€í™˜ ì‹¤íŒ¨ {node_id}: {e}")
                            continue
                else:
                    # node_listê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                    if self.verbose:
                        self.logger.info(f"node_list ì—†ìŒ - hasattr: {hasattr(self, 'node_list')}, ê°’: {getattr(self, 'node_list', None)}")
                    
                    for node_id, weight in personalization_dict.items():
                        try:
                            # Neo4jì—ì„œ ë…¸ë“œì˜ ë‚´ë¶€ ID ê°€ì ¸ì˜¤ê¸° (GDSì—ì„œ ì‚¬ìš©í•˜ëŠ” ID)
                            with self.neo4j_driver.session(database=self.database_name) as session:
                                result = session.run(
                                    "MATCH (n:Node) WHERE n.id = $node_id RETURN id(n) as gds_id", 
                                    node_id=node_id
                                )
                                record = result.single()
                                if record:
                                    gds_id = record["gds_id"]
                                    numeric_personalization_dict[gds_id] = weight
                                    if self.verbose:
                                        self.logger.info(f"ë…¸ë“œ ID {node_id[:20]}... -> GDS ID {gds_id}")
                                else:
                                    if self.verbose:
                                        self.logger.warning(f"ë…¸ë“œ ID {node_id}ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        except Exception as e:
                            if self.verbose:
                                self.logger.warning(f"ë…¸ë“œ ID ë³€í™˜ ì‹¤íŒ¨ {node_id}: {e}")
                            continue
                
                if numeric_personalization_dict:
                    if self.verbose:
                        self.logger.info(f"ìˆ«ì IDë¡œ ë³€í™˜ëœ personalization_dict: {len(numeric_personalization_dict)}ê°œ ë…¸ë“œ")
                    # personalization_dictë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ PageRank ì‹¤í–‰
                    content, scores = self.pagerank(numeric_personalization_dict, self.topN, self.sampling_area)
                else:
                    if self.verbose:
                        self.logger.warning("ìˆ«ì ID ë³€í™˜ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                    content, scores = super().retrieve_passages(query)
            else:
                if self.verbose:
                    self.logger.info("personalization_dict ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                
                # ì¼ë°˜ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ë˜, ê²°ê³¼ì—ì„œ personalization_dictë¥¼ ì¶”ì¶œí•˜ì—¬ node_list ë³€í™˜ ì‹œë„
                # super().retrieve_passages(query) ëŒ€ì‹  ì§ì ‘ retrieve_topk_nodes í˜¸ì¶œ
                if self.verbose:
                    self.logger.info("retrieve_topk_nodes ì§ì ‘ í˜¸ì¶œí•˜ì—¬ personalization_dict ìƒì„±")
                
                # retrieve_topk_nodesë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ personalization_dict ìƒì„±
                topk_nodes = self.retrieve_topk_nodes(query, top_k_nodes=self.topN)
                
                if topk_nodes:
                    if self.verbose:
                        self.logger.info(f"retrieve_topk_nodes ê²°ê³¼: {len(topk_nodes)}ê°œ ë…¸ë“œ")
                        self.logger.info(f"topk_nodes ì˜ˆì‹œ: {topk_nodes[:3]}")
                    
                    # topk_nodesì—ì„œ personalization_dict ìƒì„±
                    temp_personalization_dict = {}
                    for node_id in topk_nodes:
                        temp_personalization_dict[node_id] = 1.0
                    
                    if temp_personalization_dict:
                        if self.verbose:
                            self.logger.info(f"ì„ì‹œ personalization_dict ìƒì„±: {len(temp_personalization_dict)}ê°œ ë…¸ë“œ")
                        
                        # node_listë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜
                        numeric_personalization_dict = {}
                        for node_id, weight in temp_personalization_dict.items():
                            try:
                                # node_idê°€ ìˆ«ì ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
                                if node_id.isdigit() and int(node_id) < len(self.node_list):
                                    numeric_index = int(node_id)
                                    hash_id = self.node_list[numeric_index]
                                    with self.neo4j_driver.session(database=self.database_name) as session:
                                        result = session.run(
                                            "MATCH (n:Node) WHERE n.id = $hash_id RETURN id(n) as gds_id", 
                                            hash_id=hash_id
                                        )
                                        record = result.single()
                                        if record:
                                            gds_id = record["gds_id"]
                                            numeric_personalization_dict[str(gds_id)] = weight
                                            if self.verbose and len(numeric_personalization_dict) <= 3:
                                                self.logger.info(f"ìˆ«ì ì¸ë±ìŠ¤ {node_id} -> í•´ì‹œ ID {hash_id[:20]}... -> GDS ID {gds_id}")
                                        else:
                                            if self.verbose:
                                                self.logger.warning(f"ì¸ë±ìŠ¤ {numeric_index}ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                                elif node_id in self.node_list:
                                    # ê¸°ì¡´ ë¡œì§ (í•´ì‹œ IDì¸ ê²½ìš°)
                                    numeric_index = self.node_list.index(node_id)
                                    with self.neo4j_driver.session(database=self.database_name) as session:
                                        result = session.run(
                                            "MATCH (n:Node) WHERE n.numeric_id = $numeric_id RETURN id(n) as gds_id", 
                                            numeric_id=numeric_index
                                        )
                                        record = result.single()
                                        if record:
                                            gds_id = record["gds_id"]
                                            numeric_personalization_dict[str(gds_id)] = weight
                                            if self.verbose:
                                                self.logger.info(f"í•´ì‹œ ID {node_id[:20]}... -> ì¸ë±ìŠ¤ {numeric_index} -> GDS ID {gds_id}")
                                        else:
                                            if self.verbose:
                                                self.logger.warning(f"ì¸ë±ìŠ¤ {numeric_index}ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                                else:
                                    if self.verbose:
                                        self.logger.warning(f"node_id {node_id}ê°€ ìˆ«ì ì¸ë±ìŠ¤ë„ í•´ì‹œ IDë„ ì•„ë‹˜")
                            except Exception as e:
                                if self.verbose:
                                    self.logger.warning(f"node_id ë³€í™˜ ì‹¤íŒ¨ {node_id}: {e}")
                                continue
                        
                        if numeric_personalization_dict:
                            if self.verbose:
                                self.logger.info(f"âœ… node_list ë³€í™˜ ì„±ê³µ: {len(numeric_personalization_dict)}ê°œ ë…¸ë“œ")
                            # ë³€í™˜ëœ personalization_dictë¡œ PageRank ì‹¤í–‰
                            content, scores = self.pagerank(numeric_personalization_dict, self.topN, self.sampling_area)
                        else:
                            if self.verbose:
                                self.logger.warning("node_list ë³€í™˜ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                            content, scores = super().retrieve_passages(query)
                    else:
                        if self.verbose:
                            self.logger.warning("personalization_dict ìƒì„± ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                        content, scores = super().retrieve_passages(query)
                else:
                    if self.verbose:
                        self.logger.warning("retrieve_topk_nodes ê²°ê³¼ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                    content, scores = super().retrieve_passages(query)
            
            # None ê°’ í•„í„°ë§
            filtered_content = []
            filtered_context_ids = []
            for i, item in enumerate(content):
                if item is not None and str(item).strip():  # Noneì´ ì•„ë‹ˆê³  ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    filtered_content.append(str(item).strip())
                    filtered_context_ids.append(f"lkg_{i}")
            
            content = filtered_content
            context_ids = filtered_context_ids
            
            if self.verbose:
                self.logger.info(f"None ê°’ í•„í„°ë§ í›„: {len(content)}ê°œ ìœ íš¨í•œ ê²°ê³¼")
            
            # ì—°ê²°ëœ ë…¸ë“œë“¤ ì¶”ê°€ ê²€ìƒ‰
            if content and len(content) > 0:
                try:
                    # 1. ì¡°í•­ ê²€ìƒ‰ìœ¼ë¡œ ì—°ê²°ëœ ë…¸ë“œë“¤ ì°¾ê¸°
                    clause_results = self.search_clause_directly(query, topN=10)
                    if clause_results:
                        clause_text_ids = [result['textId'] for result in clause_results]
                        connected_nodes = self._get_nodes_from_text_ids(clause_text_ids)
                        if connected_nodes:
                            # ì—°ê²°ëœ ë…¸ë“œë“¤ì˜ ì¶”ê°€ Text ë…¸ë“œë“¤ ê°€ì ¸ì˜¤ê¸°
                            additional_texts = self.get_connected_text_nodes(
                                [node['numeric_id'] for node in connected_nodes], 
                                limit=self.connected_nodes_limit
                            )
                            
                            # ì¶”ê°€ í…ìŠ¤íŠ¸ë“¤ì„ ê¸°ì¡´ ê²°ê³¼ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
                            existing_content = set(content)
                            for additional in additional_texts:
                                if additional['text'] not in existing_content:
                                    content.append(additional['text'])
                                    context_ids.append(f"clause_connected_{additional['textId']}")
                                    existing_content.add(additional['text'])
                            
                            if self.verbose:
                                self.logger.info(f"ì¡°í•­ ê¸°ë°˜ ì—°ê²° ë…¸ë“œì—ì„œ {len(additional_texts)}ê°œ ì¶”ê°€ í…ìŠ¤íŠ¸ ë°œê²¬")
                    
                    # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ì—°ê²° ë…¸ë“œ ê²€ìƒ‰ (ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°)
                    if len(content) < topN and hasattr(self, 'node_list') and self.node_list:
                        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                        keywords = [word.strip() for word in query.split() if len(word.strip()) > 2]
                        
                        if keywords:
                            # í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ë…¸ë“œë“¤ ì°¾ê¸°
                            keyword_nodes = []
                            for node in self.node_list:
                                # node_listê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
                                if isinstance(node, str):
                                    node_name = node.lower()
                                else:
                                    node_name = node.get('name', '').lower()
                                
                                if any(keyword.lower() in node_name for keyword in keywords):
                                    if isinstance(node, str):
                                        # ë¬¸ìì—´ì¸ ê²½ìš° node_listì—ì„œ ì¸ë±ìŠ¤ ì°¾ê¸°
                                        try:
                                            node_index = self.node_list.index(node)
                                            keyword_nodes.append(node_index)
                                        except ValueError:
                                            continue
                                    else:
                                        keyword_nodes.append(node.get('numeric_id'))
                            
                            if keyword_nodes:
                                # í‚¤ì›Œë“œ ë…¸ë“œë“¤ì—ì„œ ì—°ê²°ëœ Text ë…¸ë“œë“¤ ê°€ì ¸ì˜¤ê¸°
                                additional_texts = self.get_connected_text_nodes(
                                    keyword_nodes, 
                                    limit=self.connected_nodes_limit
                                )
                                
                                # ì¶”ê°€ í…ìŠ¤íŠ¸ë“¤ì„ ê¸°ì¡´ ê²°ê³¼ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
                                existing_content = set(content)
                                for additional in additional_texts:
                                    if additional['text'] not in existing_content:
                                        content.append(additional['text'])
                                        context_ids.append(f"keyword_connected_{additional['textId']}")
                                        existing_content.add(additional['text'])
                                
                                if self.verbose:
                                    self.logger.info(f"í‚¤ì›Œë“œ ê¸°ë°˜ ì—°ê²° ë…¸ë“œì—ì„œ {len(additional_texts)}ê°œ ì¶”ê°€ í…ìŠ¤íŠ¸ ë°œê²¬")
                
                except Exception as e:
                    if self.verbose:
                        self.logger.warning(f"ì—°ê²°ëœ ë…¸ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            
            if self.verbose:
                self.logger.info(f"ìµœì¢… LKG ê²€ìƒ‰ ê²°ê³¼: {len(content)}ê°œ (ì—°ê²°ëœ ë…¸ë“œ í¬í•¨)")
            
            return content, context_ids
            
        except Exception as e:
            if self.verbose:
                self.logger.error(f"ì¼ë°˜ LKG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return [], []
    
    def _get_nodes_from_text_ids(self, text_ids):
        """
        Text ë…¸ë“œ IDë“¤ë¡œë¶€í„° ì—°ê²°ëœ Nodeë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        """
        if not text_ids:
            return []
            
        try:
            with self.neo4j_driver.session(database=self.database_name) as session:
                query = """
                UNWIND $text_ids AS text_id
                MATCH (n:Node)-[:Source]->(t:Text {numeric_id: text_id})
                RETURN DISTINCT n.numeric_id as numeric_id, 
                               n.name as name,
                               n.type as type
                """
                
                result = session.run(query, text_ids=text_ids)
                return [dict(record) for record in result]
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"Text IDì—ì„œ Node ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def convert_numeric_id_to_name(self, numeric_id):
        """
        Enhanced version of convert_numeric_id_to_name using node_list like original
        """
        try:
            if numeric_id.isdigit():
                # FAISS ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ node_list ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
                faiss_index = int(numeric_id)
                
                # node_listì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë…¸ë“œ ID ê°€ì ¸ì˜¤ê¸°
                if hasattr(self, 'node_list') and faiss_index < len(self.node_list):
                    node_id = self.node_list[faiss_index]
                    
                    # GraphMLì—ì„œ ë…¸ë“œ íƒ€ì… í™•ì¸ (entity íƒ€ì…ë§Œ Neo4jì—ì„œ ê²€ìƒ‰)
                    if hasattr(self, 'kg_graph') and node_id in self.kg_graph.nodes:
                        node_type = self.kg_graph.nodes[node_id].get('type', '')
                        if 'entity' not in node_type:
                            # entityê°€ ì•„ë‹Œ ê²½ìš° (event, concept ë“±)ëŠ” ë…¸ë“œ ID ê·¸ëŒ€ë¡œ ë°˜í™˜
                            return node_id
                    
                    # Neo4jì—ì„œ í•´ë‹¹ ë…¸ë“œ IDë¡œ ê²€ìƒ‰ (entity íƒ€ì…ë§Œ)
                    try:
                        with self.neo4j_driver.session(database=self.database_name) as session:
                            result = session.run(
                                "MATCH (n:Node) WHERE n.id = $node_id RETURN n.name as name", 
                                node_id=node_id
                            )
                            record = result.single()
                            if record and record['name']:
                                return record['name']
                            else:
                                # Neo4jì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë…¸ë“œ ID ê·¸ëŒ€ë¡œ ë°˜í™˜
                                return node_id
                    except Exception as neo4j_error:
                        if self.verbose:
                            self.logger.debug(f"Neo4j query failed for node_id {node_id}: {neo4j_error}")
                        return node_id
                else:
                    if self.verbose:
                        self.logger.warning(f"FAISS ì¸ë±ìŠ¤ {faiss_index}ê°€ node_list ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
                    return f"OutOfRange_Node_{numeric_id}"
            else:
                return numeric_id
        except Exception as e:
            if self.verbose:
                self.logger.warning(f"Error converting numeric_id {numeric_id}: {e}")
            return f"Error_Node_{numeric_id}"
    
    def retrieve_topk_nodes(self, query, top_k_nodes=2):
        """
        Enhanced version of retrieve_topk_nodes with better error handling
        """
        try:
            # extract entities from the query
            entities = self.ner(query)
            if self.verbose:
                self.logger.info(f"largekgRAG : LLM Extracted entities: {entities}")
            if len(entities) == 0:
                entities = [query]
            num_entities = len(entities)
            initial_nodes = []
            
            for entity in entities:
                try:
                    entity_embedding = self.sentence_encoder.encode([entity])
                    D, I = self.node_faiss_index.search(entity_embedding, top_k_nodes)
                    if self.verbose:
                        self.logger.info(f"largekgRAG : Search results - Distances: {D}, Indices: {I}")
                    initial_nodes += [str(i) for i in I[0]]
                except Exception as e:
                    if self.verbose:
                        self.logger.warning(f"Error searching for entity '{entity}': {e}")
                    continue
                    
            if self.verbose:
                self.logger.info(f"largekgRAG : Initial nodes: {initial_nodes}")
            
            if not initial_nodes:
                if self.verbose:
                    self.logger.warning("No initial nodes found")
                return []
            
            name_id_map = {}
            for node_id in initial_nodes:
                try:
                    name = self.convert_numeric_id_to_name(node_id)
                    if name and not name.startswith("Error_") and not name.startswith("Unknown_"):
                        name_id_map[name] = node_id
                except Exception as e:
                    if self.verbose:
                        self.logger.warning(f"Error converting node_id {node_id}: {e}")
                    continue
                    
            if not name_id_map:
                if self.verbose:
                    self.logger.warning("No valid nodes found after conversion")
                return []
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"largekgRAG : Error in retrieve_topk_nodes: {e}")
                import traceback
                self.logger.error(f"largekgRAG : Traceback: {traceback.format_exc()}")
            return []  
            
        topk_nodes = list(set(initial_nodes))
        
        # convert the numeric id to string and filter again then return numeric id
        keywords_before_filter = [self.convert_numeric_id_to_name(n) for n in initial_nodes if n in name_id_map.values()]
        
        if not keywords_before_filter:
            if self.verbose:
                self.logger.warning("No keywords for filtering")
            return []
            
        filtered_keywords = self.llm_generator.large_kg_filter_keywords_with_entity(query, keywords_before_filter)
    
        # Second pass: Add filtered keywords
        filtered_top_k_nodes = []
        filter_log_dict = {}
        match_threshold = 0.8
        if self.verbose:
            self.logger.info(f"largekgRAG : Filtered Before Match Keywords Candidate: {filtered_keywords}")
            
        for keyword in filtered_keywords:
            # Check for an exact match first
            if keyword in name_id_map:
                filtered_top_k_nodes.append(name_id_map[keyword])
                filter_log_dict[keyword] = name_id_map[keyword]
            else:
                # Look for close matches using difflib's get_close_matches
                close_matches = get_close_matches(keyword, name_id_map.keys(), n=1, cutoff=match_threshold)
                
                if close_matches:
                    # If a close match is found, add the corresponding node
                    filtered_top_k_nodes.append(name_id_map[close_matches[0]])
                
                filter_log_dict[keyword] = name_id_map[close_matches[0]] if close_matches else None
                
        if self.verbose:
            self.logger.info(f"largekgRAG : Filtered After Match Keywords Candidate: {filter_log_dict}")
        
        topk_nodes = list(set(filtered_top_k_nodes))
        if len(topk_nodes) > 2 * num_entities:
            topk_nodes = topk_nodes[:2 * num_entities]
            
        if self.verbose:
            self.logger.info(f"largekgRAG : Final topk_nodes: {topk_nodes}")
            
        return topk_nodes
    
    def retrieve(self, query, topN=5):
        """
        ê¸°ë³¸ retrieve ë©”ì„œë“œë¥¼ í–¥ìƒëœ ë²„ì „ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ
        """
        if self.verbose:
            self.logger.info(f"í–¥ìƒëœ ê²€ìƒ‰ ì‹œì‘: {query}")
        
        # GDS ê·¸ë˜í”„ í™•ì¸ (ìˆ˜ì •ëœ ë°©ì‹)
        try:
            # GDS ê·¸ë˜í”„ ì¡´ì¬ í™•ì¸
            with self.neo4j_driver.session(database=self.database_name) as session:
                result = session.run("CALL gds.graph.list() YIELD graphName RETURN graphName")
                graphs = [record["graphName"] for record in result]
                if 'largekgrag_graph' not in graphs:
                    if self.verbose:
                        self.logger.warning("GDS ê·¸ë˜í”„ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                    return super().retrieve_passages(query)
                
                # GDS ê·¸ë˜í”„ ì •ë³´ í™•ì¸ (gds.graph.info ëŒ€ì‹  ê°„ë‹¨í•œ í™•ì¸)
                if self.verbose:
                    self.logger.info(f"GDS ê·¸ë˜í”„ í™•ì¸: largekgrag_graph ì¡´ì¬")
                    
        except Exception as e:
            if self.verbose:
                self.logger.warning(f"GDS ê·¸ë˜í”„ í™•ì¸ ì‹¤íŒ¨: {e}")
            return super().retrieve_passages(query)
        
        # ì¡°í•­ ì§ˆë¬¸ íŒë‹¨
        is_clause_question = self.is_clause_question(query)
        if self.verbose:
            self.logger.info(f"ì¡°í•­ ì§ˆë¬¸ íŒë‹¨ - ì§ˆë¬¸: '{query}'")
        
        if is_clause_question:
            if self.verbose:
                self.logger.info("ì¡°í•­ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€ - ì§ì ‘ ì¡°í•­ ê²€ìƒ‰ ì‹œë„")
        
            # ì¡°í•­ ê²€ìƒ‰ ì‹œë„
            clause_results = self.search_clause_directly(query, topN)
            if clause_results:
                if self.verbose:
                    self.logger.info(f"ì´ ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼: {len(clause_results)}ê°œ (ì¤‘ë³µ ì œê±° í›„)")
                
                # ì¡°í•­ ê²€ìƒ‰ ê²°ê³¼ë¥¼ [content, context_ids] í˜•íƒœë¡œ ë³€í™˜
                content = [result['text'] for result in clause_results]
                context_ids = [result['textId'] for result in clause_results]
                return content, context_ids
            else:
                if self.verbose:
                    self.logger.info("ì¡°í•­ ê²€ìƒ‰ì—ì„œ ê²°ê³¼ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        
        # GDS PageRank ì‚¬ìš©í•œ ê²€ìƒ‰ ì‹œë„
        if self.verbose:
            self.logger.info("GDS PageRank ì‚¬ìš©í•œ ê²€ìƒ‰ ì‹œë„")
        
        try:
            # 1. FAISSë¡œ ì´ˆê¸° ë…¸ë“œ ê²€ìƒ‰
            topk_nodes = self.retrieve_topk_nodes(query, top_k_nodes=50)
            if self.verbose:
                self.logger.info(f"retrieve_topk_nodes ê²°ê³¼: {len(topk_nodes)}ê°œ ë…¸ë“œ")
                self.logger.info(f"topk_nodes ì˜ˆì‹œ: {topk_nodes[:3]}")
            
            if not topk_nodes:
                if self.verbose:
                    self.logger.warning("FAISS ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                return super().retrieve_passages(query)
            
            # 2. node_list ì‚¬ìš©í•˜ì—¬ GDS ID ë³€í™˜
            if self.verbose:
                self.logger.info(f"node_list ì‚¬ìš©í•˜ì—¬ GDS ID ë³€í™˜ ì‹œë„ (ê¸¸ì´: {len(self.node_list)})")
            
            personalization_dict = {}
            converted_count = 0
            
            for i, node_id in enumerate(topk_nodes):
                try:
                    # ìˆ«ì ì¸ë±ìŠ¤ë¥¼ í•´ì‹œ IDë¡œ ë³€í™˜
                    if isinstance(node_id, str) and node_id.isdigit():
                        node_index = int(node_id)
                        if 0 <= node_index < len(self.node_list):
                            hash_id = self.node_list[node_index]
                            if self.verbose and i < 3:
                                self.logger.info(f"ì¸ë±ìŠ¤ {node_index} -> í•´ì‹œ ID {hash_id[:20]}...")
                            
                            # Neo4jì—ì„œ GDS ID ì°¾ê¸°
                            with self.neo4j_driver.session(database=self.database_name) as session:
                                result = session.run(
                                    "MATCH (n) WHERE n.id = $hash_id RETURN n.numeric_id as gds_id",
                                    hash_id=hash_id
                                )
                                record = result.single()
                                
                                if record and record['gds_id'] is not None:
                                    gds_id = record['gds_id']
                                    personalization_dict[str(gds_id)] = 1.0
                                    converted_count += 1
                                    if self.verbose and i < 3:
                                        self.logger.info(f"âœ… GDS ID ë³€í™˜ ì„±ê³µ: {gds_id}")
                                else:
                                    if self.verbose:
                                        self.logger.warning(f"í•´ì‹œ ID {hash_id[:20]}...ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        else:
                            if self.verbose:
                                self.logger.warning(f"ì¸ë±ìŠ¤ {node_index}ê°€ node_list ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨")
                    else:
                        if self.verbose:
                            self.logger.warning(f"ì˜ëª»ëœ ë…¸ë“œ ID í˜•ì‹: {node_id}")
                        
                except Exception as e:
                    if self.verbose:
                        self.logger.warning(f"ë…¸ë“œ {node_id} ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            if self.verbose:
                self.logger.info(f"âœ… í•´ì‹œ ID ë³€í™˜ ì„±ê³µ: {converted_count}ê°œ ë…¸ë“œ")
            
            if not personalization_dict:
                if self.verbose:
                    self.logger.warning("GDS ID ë³€í™˜ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                # ì¼ë°˜ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ë˜, ê²°ê³¼ì—ì„œ personalization_dictë¥¼ ì¶”ì¶œí•˜ì—¬ node_list ë³€í™˜ ì‹œë„
                if self.verbose:
                    self.logger.info("retrieve_topk_nodes ì§ì ‘ í˜¸ì¶œí•˜ì—¬ personalization_dict ìƒì„±")
                
                # retrieve_topk_nodesë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ personalization_dict ìƒì„±
                topk_nodes = self.retrieve_topk_nodes(query, top_k_nodes=self.topN)
                
                if topk_nodes:
                    if self.verbose:
                        self.logger.info(f"retrieve_topk_nodes ê²°ê³¼: {len(topk_nodes)}ê°œ ë…¸ë“œ")
                        self.logger.info(f"topk_nodes ì˜ˆì‹œ: {topk_nodes[:3]}")
                    
                    # topk_nodesì—ì„œ personalization_dict ìƒì„±
                    temp_personalization_dict = {}
                    for node_id in topk_nodes:
                        temp_personalization_dict[node_id] = 1.0
                    
                    if temp_personalization_dict:
                        if self.verbose:
                            self.logger.info(f"ì„ì‹œ personalization_dict ìƒì„±: {len(temp_personalization_dict)}ê°œ ë…¸ë“œ")
                        
                        # node_listë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜
                        numeric_personalization_dict = {}
                        for node_id, weight in temp_personalization_dict.items():
                            try:
                                # node_idê°€ ìˆ«ì ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
                                if node_id.isdigit() and int(node_id) < len(self.node_list):
                                    numeric_index = int(node_id)
                                    hash_id = self.node_list[numeric_index]
                                    with self.neo4j_driver.session(database=self.database_name) as session:
                                        result = session.run(
                                            "MATCH (n) WHERE n.id = $hash_id RETURN n.numeric_id as gds_id",
                                            hash_id=hash_id
                                        )
                                        record = result.single()
                                        if record and record['gds_id'] is not None:
                                            gds_id = record['gds_id']
                                            numeric_personalization_dict[str(gds_id)] = weight
                                            if self.verbose and len(numeric_personalization_dict) <= 3:
                                                self.logger.info(f"ìˆ«ì ì¸ë±ìŠ¤ {node_id} -> í•´ì‹œ ID {hash_id[:20]}... -> GDS ID {gds_id}")
                                        else:
                                            if self.verbose:
                                                self.logger.warning(f"ì¸ë±ìŠ¤ {numeric_index}ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                                elif node_id in self.node_list:
                                    # ê¸°ì¡´ ë¡œì§ (í•´ì‹œ IDì¸ ê²½ìš°)
                                    numeric_index = self.node_list.index(node_id)
                                    with self.neo4j_driver.session(database=self.database_name) as session:
                                        result = session.run(
                                            "MATCH (n) WHERE n.numeric_id = $numeric_id RETURN id(n) as gds_id", 
                                            numeric_id=numeric_index
                                        )
                                        record = result.single()
                                        if record:
                                            gds_id = record["gds_id"]
                                            numeric_personalization_dict[str(gds_id)] = weight
                                            if self.verbose:
                                                self.logger.info(f"í•´ì‹œ ID {node_id[:20]}... -> ì¸ë±ìŠ¤ {numeric_index} -> GDS ID {gds_id}")
                                        else:
                                            if self.verbose:
                                                self.logger.warning(f"ì¸ë±ìŠ¤ {numeric_index}ì— ëŒ€í•œ GDS IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                                else:
                                    if self.verbose:
                                        self.logger.warning(f"node_id {node_id}ê°€ ìˆ«ì ì¸ë±ìŠ¤ë„ í•´ì‹œ IDë„ ì•„ë‹˜")
                            except Exception as e:
                                if self.verbose:
                                    self.logger.warning(f"node_id ë³€í™˜ ì‹¤íŒ¨ {node_id}: {e}")
                                continue
                        
                        if numeric_personalization_dict:
                            if self.verbose:
                                self.logger.info(f"âœ… node_list ë³€í™˜ ì„±ê³µ: {len(numeric_personalization_dict)}ê°œ ë…¸ë“œ")
                            # ë³€í™˜ëœ personalization_dictë¡œ PageRank ì‹¤í–‰
                            content, scores = self.pagerank(numeric_personalization_dict, self.topN, self.sampling_area)
                        else:
                            if self.verbose:
                                self.logger.warning("node_list ë³€í™˜ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                            content, scores = super().retrieve_passages(query)
                    else:
                        if self.verbose:
                            self.logger.warning("personalization_dict ìƒì„± ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                        content, scores = super().retrieve_passages(query)
                else:
                    if self.verbose:
                        self.logger.warning("retrieve_topk_nodes ê²°ê³¼ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                    content, scores = super().retrieve_passages(query)
            
            # 3. PageRank ì‹¤í–‰
            if self.verbose:
                self.logger.info(f"PageRank ì‹¤í–‰ - personalization_dict: {len(personalization_dict)}ê°œ ë…¸ë“œ")
            
            # GDS ê·¸ë˜í”„ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            graph = self.gds_driver.graph.get('largekgrag_graph')
            
            # GDS ê·¸ë˜í”„ì˜ ì‹¤ì œ ë…¸ë“œ ID í™•ì¸
            try:
                # GDS ê·¸ë˜í”„ì˜ ëª¨ë“  ë…¸ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                all_nodes = self.gds_driver.graph.nodeProperty.stream(
                    graph, 
                    node_property='numeric_id'
                )
                
                if self.verbose:
                    self.logger.info(f"GDS ê·¸ë˜í”„ ì´ ë…¸ë“œ ìˆ˜: {len(all_nodes)}")
                    if len(all_nodes) > 0:
                        self.logger.info(f"GDS ê·¸ë˜í”„ ë…¸ë“œ ID ë²”ìœ„: {all_nodes['nodeId'].min()} ~ {all_nodes['nodeId'].max()}")
                
                # GDS ë…¸ë“œ IDì™€ Neo4j numeric_id ë§¤í•‘ ìƒì„±
                gds_to_numeric = {}
                for _, row in all_nodes.iterrows():
                    gds_id = row['nodeId']
                    numeric_id = row.get('numeric_id')
                    if numeric_id is not None:
                        gds_to_numeric[gds_id] = numeric_id
                
                if self.verbose:
                    self.logger.info(f"GDS-Neo4j ë§¤í•‘ ìƒì„±: {len(gds_to_numeric)}ê°œ")
                
                # ë§¤í•‘ì´ ì—†ìœ¼ë©´ ì§ì ‘ Neo4jì—ì„œ í™•ì¸
                if len(gds_to_numeric) == 0:
                    if self.verbose:
                        self.logger.warning("GDS-Neo4j ë§¤í•‘ì´ ì—†ìŒ - ì§ì ‘ Neo4jì—ì„œ í™•ì¸")
                    
                    # Neo4jì—ì„œ numeric_idê°€ ìˆëŠ” ë…¸ë“œë“¤ í™•ì¸
                    with self.neo4j_driver.session(database=self.database_name) as session:
                        result = session.run("MATCH (n:Node) WHERE n.numeric_id IS NOT NULL RETURN n.numeric_id as numeric_id LIMIT 10")
                        numeric_ids = [record['numeric_id'] for record in result]
                        if self.verbose:
                            self.logger.info(f"Neo4jì—ì„œ ì°¾ì€ numeric_id ì˜ˆì‹œ: {numeric_ids[:5]}")
                    
                # GDS ê·¸ë˜í”„ì˜ ì‹¤ì œ ë…¸ë“œ IDë“¤ì„ ê°€ì ¸ì˜¤ê¸°
                try:
                    # GDS ê·¸ë˜í”„ì˜ ëª¨ë“  ë…¸ë“œ ID ì¡°íšŒ
                    gds_nodes = self.gds_driver.graph.list_nodes(graph)
                    if gds_nodes:
                        for i, gds_id in enumerate(gds_nodes):
                            gds_to_numeric[gds_id] = i  # GDS ID -> ìˆœì„œ ì¸ë±ìŠ¤ ë§¤í•‘
                    else:
                        # ëŒ€ì•ˆ: GDS ê·¸ë˜í”„ í¬ê¸°ë¡œë¶€í„° ë…¸ë“œ ID ë²”ìœ„ ì¶”ì •
                        graph_info = self.gds_driver.graph.get(graph)
                        node_count = graph_info.get('nodeCount', 0)
                        for i in range(node_count):
                            gds_to_numeric[i] = i  # GDS ID = ì¸ë±ìŠ¤
                except Exception as e:
                    if self.verbose:
                        self.logger.warning(f"GDS ë…¸ë“œ ID ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    # ê¸°ë³¸ ë§¤í•‘ ì‚¬ìš©
                    for i in range(len(personalization_dict)):
                        gds_to_numeric[i] = i
            
                # personalization_dictì˜ numeric_idë¥¼ GDS nodeIdë¡œ ë³€í™˜
                valid_source_nodes = []
                for node_id in personalization_dict.keys():
                    numeric_id = int(node_id)
                    # numeric_idì— í•´ë‹¹í•˜ëŠ” GDS nodeId ì°¾ê¸°
                    for gds_id, mapped_numeric_id in gds_to_numeric.items():
                        if mapped_numeric_id == numeric_id:
                            valid_source_nodes.append(gds_id)
                            break
                
                if self.verbose:
                    self.logger.info(f"ìœ íš¨í•œ sourceNodes: {len(valid_source_nodes)}ê°œ / {len(personalization_dict)}ê°œ")
                
                if not valid_source_nodes:
                    if self.verbose:
                        self.logger.warning("ìœ íš¨í•œ sourceNodesê°€ ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                    return super().retrieve_passages(query)
                
                # GDS PageRank ì‹¤í–‰ì„ ìœ„í•œ ë…¸ë“œ ID ë³€í™˜
                # sourceNodesëŠ” GDS ë‚´ë¶€ ë…¸ë“œ IDë¥¼ ì‚¬ìš©
                source_nodes_gds = valid_source_nodes  # ì´ë¯¸ GDS ID
                
                # personalization_dictë¥¼ GDS IDë¡œ ë³€í™˜
                gds_personalization_dict = {}
                for node_id in personalization_dict.keys():
                    numeric_id = int(node_id)
                    # numeric_idì— í•´ë‹¹í•˜ëŠ” GDS nodeId ì°¾ê¸°
                    for gds_id, mapped_numeric_id in gds_to_numeric.items():
                        if mapped_numeric_id == numeric_id:
                            gds_personalization_dict[gds_id] = personalization_dict[node_id]
                            break
                
                if self.verbose:
                    self.logger.info(f"GDS personalization_dict: {len(gds_personalization_dict)}ê°œ ë…¸ë“œ")
                    self.logger.info(f"sourceNodes: {len(source_nodes_gds)}ê°œ ë…¸ë“œ")
                
                # GDS PageRank ì‹¤í–‰ - personalizationê³¼ sourceNodes ëª¨ë‘ ì‚¬ìš©
                # sourceNodesëŠ” GDS ë‚´ë¶€ ë…¸ë“œ ID ë¦¬ìŠ¤íŠ¸, personalizationì€ ë…¸ë“œ IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
                pagerank_result = self.gds_driver.pageRank.stream(
                    graph,
                    maxIterations=20,
                    dampingFactor=0.85,
                    sourceNodes=source_nodes_gds,
                    personalization=gds_personalization_dict
                )
                
                if self.verbose:
                    self.logger.info(f"PageRank ê²°ê³¼: {len(pagerank_result)}ê°œ ë…¸ë“œ")
                
                # PageRank ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ê²€ìƒ‰
                if not pagerank_result.empty:
                    # PageRank ê²°ê³¼ì—ì„œ ìƒìœ„ ë…¸ë“œë“¤ì˜ GDS nodeId ì¶”ì¶œ
                    top_gds_nodes = pagerank_result.head(topN)['nodeId'].tolist()
                    
                    # GDS nodeIdë¥¼ numeric_idë¡œ ë³€í™˜
                    top_numeric_nodes = []
                    for gds_id in top_gds_nodes:
                        if gds_id in gds_to_numeric:
                            top_numeric_nodes.append(gds_to_numeric[gds_id])
                    
                    if top_numeric_nodes:
                        # ì´ ë…¸ë“œë“¤ë¡œë¶€í„° í…ìŠ¤íŠ¸ ê²€ìƒ‰
                        with self.neo4j_driver.session(database=self.database_name) as session:
                            query_text = """
                            UNWIND $nodeIds AS nodeId
                            MATCH (n:Node {numeric_id: nodeId})-[:Source]->(t:Text)
                            RETURN t.text AS text, t.numeric_id AS textId
                            ORDER BY nodeId
                            """
                            result = session.run(query_text, nodeIds=top_numeric_nodes)
                            texts = [record["text"] for record in result if record["text"]]
                            
                            if texts:
                                if self.verbose:
                                    self.logger.info(f"PageRank ê¸°ë°˜ ê²€ìƒ‰ ì„±ê³µ: {len(texts)}ê°œ ê²°ê³¼")
                                return texts, [f"pagerank_{i}" for i in range(len(texts))]
                
                if self.verbose:
                    self.logger.warning("PageRank ê¸°ë°˜ ê²€ìƒ‰ ì‹¤íŒ¨ - ì¼ë°˜ ê²€ìƒ‰ ì‚¬ìš©")
                
                # GDS PageRank ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°©ë²•: personalization_dictì˜ ë…¸ë“œë“¤ë¡œ ì§ì ‘ ê²€ìƒ‰
                if personalization_dict:
                    if self.verbose:
                        self.logger.info("personalization_dictë¥¼ ì‚¬ìš©í•œ ì§ì ‘ ê²€ìƒ‰ ì‹œë„")
                    
                    # personalization_dictì˜ ë…¸ë“œë“¤ë¡œ ì§ì ‘ í…ìŠ¤íŠ¸ ê²€ìƒ‰
                    with self.neo4j_driver.session(database=self.database_name) as session:
                        query_text = """
                        UNWIND $nodeIds AS nodeId
                        MATCH (n:Node {numeric_id: nodeId})-[:Source]->(t:Text)
                        RETURN t.text AS text, t.numeric_id AS textId
                        ORDER BY nodeId
                        LIMIT $limit
                        """
                        node_ids = [int(node_id) for node_id in personalization_dict.keys()]
                        result = session.run(query_text, nodeIds=node_ids, limit=self.topN)
                        texts = [record["text"] for record in result if record["text"]]
                        
                        if texts:
                            if self.verbose:
                                self.logger.info(f"ì§ì ‘ ê²€ìƒ‰ ì„±ê³µ: {len(texts)}ê°œ ê²°ê³¼")
                            return texts, [f"direct_{i}" for i in range(len(texts))]
                
                return super().retrieve_passages(query)
                
            except Exception as e:
                if self.verbose:
                    self.logger.error(f"GDS PageRank ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                return super().retrieve_passages(query)
                
        except Exception as e:
            if self.verbose:
                self.logger.error(f"GDS PageRank ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return super().retrieve_passages(query)
