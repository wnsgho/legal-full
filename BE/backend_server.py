#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AutoSchemaKG ë°±ì—”ë“œ ì„œë²„
FastAPIë¥¼ ì‚¬ìš©í•œ REST API ì„œë²„
"""

import os
import sys
import json
import logging
import shutil
import uuid
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any
from contextlib import asynccontextmanager

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •ì— ì¸ì½”ë”© ì¶”ê°€ (Windows cp949 ì˜¤ë¥˜ í•´ê²°)
import sys
import io
import warnings

# stdoutì„ utf-8ë¡œ ì„¤ì •
if sys.platform.startswith('win'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì–µì œ
warnings.filterwarnings("ignore")
logging.getLogger("faiss.loader").setLevel(logging.WARNING)
logging.getLogger("sentence_transformers").setLevel(logging.WARNING)
logging.getLogger("nltk").setLevel(logging.WARNING)
logging.getLogger("transformers").setLevel(logging.WARNING)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ì „ì—­ ë³€ìˆ˜
rag_system = None
neo4j_driver = None
pipeline_status = {}  # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬
uploaded_files = {}   # ì—…ë¡œë“œëœ íŒŒì¼ ê´€ë¦¬

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
UPLOAD_DIR = Path(__file__).parent.parent / "uploads"
UPLOAD_DIR.mkdir(exist_ok=True)

def restore_uploaded_files():
    """ì„œë²„ ì‹œì‘ ì‹œ ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ uploaded_files ë³µêµ¬ (ê°€ì¥ ìµœê·¼ íŒŒì¼ë§Œ)"""
    global uploaded_files
    
    if not UPLOAD_DIR.exists():
        return
    
    # íŒŒì¼ë“¤ì„ ìˆ˜ì • ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœê·¼ íŒŒì¼ë§Œ ë³µêµ¬
    files_with_time = []
    for file_path in UPLOAD_DIR.iterdir():
        if file_path.is_file():
            files_with_time.append((file_path, file_path.stat().st_mtime))
    
    # ìˆ˜ì • ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
    files_with_time.sort(key=lambda x: x[1], reverse=True)
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ë§Œ ë³µêµ¬
    if files_with_time:
        file_path, _ = files_with_time[0]
        filename = file_path.name
        if '_' in filename:
            file_id = filename.split('_')[0]
            original_filename = '_'.join(filename.split('_')[1:])
            
            # íŒŒì¼ ì •ë³´ ë³µêµ¬
            uploaded_files[file_id] = {
                "filename": original_filename,
                "file_path": str(file_path),
                "upload_time": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
                "file_size": file_path.stat().st_size
            }
            
            logger.info(f"âœ… ê°€ì¥ ìµœê·¼ ì—…ë¡œë“œ íŒŒì¼ ë³µêµ¬: {original_filename} (ID: {file_id})")
            
            # ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤ì€ ì‚­ì œ (ì„ íƒì‚¬í•­)
            for other_file, _ in files_with_time[1:]:
                try:
                    other_file.unlink()
                    logger.info(f"ğŸ—‘ï¸ ì´ì „ íŒŒì¼ ì‚­ì œ: {other_file.name}")
                except Exception as e:
                    logger.warning(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {other_file.name}: {e}")

def load_risk_checklist():
    """ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
    try:
        # BE í´ë” ê¸°ì¤€ìœ¼ë¡œ ìœ„í—˜ì¡°í•­.txt íŒŒì¼ ì°¾ê¸°
        risk_file = Path(__file__).parent / "ìœ„í—˜ì¡°í•­.txt"
        
        if risk_file.exists():
            with open(risk_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content:
                    risk_items = [item.strip() for item in content.split('\n') if item.strip()]
                    return '\n'.join([f"{i+1}. {item}" for i, item in enumerate(risk_items)])
        else:
            logger.warning(f"âš ï¸ ìœ„í—˜ì¡°í•­.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {risk_file.absolute()}")
            return "ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"âŒ ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return "ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def find_existing_keyword():
    """ê¸°ì¡´ ì„ë² ë”© ë°ì´í„°ê°€ ìˆëŠ” í‚¤ì›Œë“œ ì°¾ê¸°"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ import ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œ)
    import_dir = Path(os.getenv('IMPORT_DIRECTORY', 'BE/import'))
    logger.info(f"ğŸ” ì„ë² ë”© ë°ì´í„° íƒìƒ‰ ì¤‘... import_dir: {import_dir.absolute()}")
    
    if not import_dir.exists():
        logger.warning(f"âŒ import ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {import_dir.absolute()}")
        return None
    
    # import í´ë”ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸°
    for keyword_dir in import_dir.iterdir():
        if keyword_dir.is_dir():
            logger.info(f"ğŸ“ í‚¤ì›Œë“œ ë””ë ‰í† ë¦¬ ë°œê²¬: {keyword_dir.name}")
            precompute_dir = keyword_dir / os.getenv('PRECOMPUTE_DIRECTORY', 'precompute')
            logger.info(f"ğŸ” precompute ë””ë ‰í† ë¦¬ í™•ì¸: {precompute_dir.absolute()}")
            
            if precompute_dir.exists():
                # FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                faiss_files = list(precompute_dir.glob("*_faiss.index"))
                logger.info(f"ğŸ“Š FAISS íŒŒì¼ ê°œìˆ˜: {len(faiss_files)}")
                if faiss_files:
                    logger.info(f"âœ… ê¸°ì¡´ ì„ë² ë”© ë°ì´í„° ë°œê²¬: {keyword_dir.name}")
                    return keyword_dir.name
                else:
                    logger.info(f"âš ï¸ precompute ë””ë ‰í† ë¦¬ëŠ” ìˆì§€ë§Œ FAISS íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {keyword_dir.name}")
            else:
                logger.info(f"âš ï¸ precompute ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {keyword_dir.name}")
    
    logger.warning("âŒ ì„ë² ë”© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return None

def check_and_load_existing_data():
    """ì„œë²„ ì‹œì‘ ì‹œ ê¸°ì¡´ Neo4j ë°ì´í„° í™•ì¸ ë° ë¡œë“œ"""
    global rag_system, neo4j_driver
    
    try:
        logger.info("ğŸ” ê¸°ì¡´ Neo4j ë°ì´í„° í™•ì¸ ì¤‘...")
        
        # ë¨¼ì € Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            from neo4j import GraphDatabase
            neo4j_uri = os.getenv('NEO4J_URI', 'neo4j://127.0.0.1:7687')
            neo4j_user = os.getenv('NEO4J_USER', 'neo4j')
            neo4j_password = os.getenv('NEO4J_PASSWORD', '')
            neo4j_database = os.getenv('NEO4J_DATABASE', 'neo4j')
            
            driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
            
            # Neo4jì—ì„œ ë…¸ë“œ ìˆ˜ í™•ì¸
            with driver.session(database=neo4j_database) as session:
                result = session.run("MATCH (n) RETURN count(n) as node_count")
                node_count = result.single()["node_count"]
                
                if node_count > 0:
                    logger.info(f"âœ… ê¸°ì¡´ Neo4j ë°ì´í„° ë°œê²¬: {node_count}ê°œ ë…¸ë“œ")
                    
                    # GDS ê·¸ë˜í”„ í™•ì¸ ë° ìƒì„±
                    try:
                        from .experiment.create_gds_graph import create_gds_graph
                        logger.info("ğŸ”„ GDS ê·¸ë˜í”„ í™•ì¸ ë° ìƒì„± ì¤‘...")
                        create_gds_graph()
                        logger.info("âœ… GDS ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
                    except Exception as e:
                        logger.warning(f"âš ï¸ GDS ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {e}")
                    
                    # ê¸°ì¡´ ì„ë² ë”© ë°ì´í„°ê°€ ìˆëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
                    existing_keyword = find_existing_keyword()
                    if existing_keyword:
                        # í™˜ê²½ë³€ìˆ˜ì— í‚¤ì›Œë“œ ì„¤ì •
                        os.environ['KEYWORD'] = existing_keyword
                        logger.info(f"ğŸ”‘ í‚¤ì›Œë“œ ì„¤ì •: {existing_keyword}")
                        
                        # RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹œë„
                        try:
                            from .experiment.run_questions_v3_with_concept import load_enhanced_rag_system
                            enhanced_lkg_retriever, hippo_retriever, llm_generator, _ = load_enhanced_rag_system()
                            
                            # RAG ì‹œìŠ¤í…œ ì„¤ì •
                            rag_system = {
                                "enhanced_lkg_retriever": enhanced_lkg_retriever,
                                "hippo_retriever": hippo_retriever,
                                "llm_generator": llm_generator
                            }
                            
                            logger.info("âœ… ê¸°ì¡´ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
                            return True
                            
                        except Exception as rag_error:
                            logger.warning(f"âš ï¸ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {rag_error}")
                            return False
                    else:
                        logger.info("â„¹ï¸ ì„ë² ë”© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                        return False
                        
                else:
                    logger.info("â„¹ï¸ Neo4jì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    return False
                    
        except Exception as neo4j_error:
            logger.warning(f"âš ï¸ Neo4j ì—°ê²° ì‹¤íŒ¨: {neo4j_error}")
            return False
            
    except Exception as e:
        logger.warning(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜"""
    # ì‹œì‘ ì‹œ
    logger.info("ğŸš€ AutoSchemaKG ë°±ì—”ë“œ ì„œë²„ ì‹œì‘ ì¤‘...")
    restore_uploaded_files()
    
    # ê¸°ì¡´ Neo4j ë°ì´í„° í™•ì¸ ë° ë¡œë“œ
    data_loaded = check_and_load_existing_data()
    if not data_loaded:
        logger.info("â„¹ï¸ ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    yield
    # ì¢…ë£Œ ì‹œ
    logger.info("ğŸ›‘ AutoSchemaKG ë°±ì—”ë“œ ì„œë²„ ì¢…ë£Œ ì¤‘...")
    
    # Neo4j ì—°ê²° ì •ë¦¬
    if neo4j_driver:
        neo4j_driver.close()
        logger.info("âœ… Neo4j ì—°ê²° ì •ë¦¬ ì™„ë£Œ")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AutoSchemaKG Backend API",
    description="ì§€ì‹ê·¸ë˜í”„ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ë°±ì—”ë“œ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic ëª¨ë¸ë“¤
class PipelineRequest(BaseModel):
    start_step: int = 0
    keyword: Optional[str] = None

class PipelineResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None

class ChatRequest(BaseModel):
    question: str
    max_tokens: int = 8192  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
    temperature: float = 0.5

class ChatResponse(BaseModel):
    success: bool
    answer: str
    context_count: int
    processing_time: float

class HealthResponse(BaseModel):
    status: str
    timestamp: str
    version: str

class FileUploadResponse(BaseModel):
    success: bool
    file_id: str
    filename: str
    message: str

class PipelineStatusResponse(BaseModel):
    success: bool
    status: str
    progress: int
    message: str
    data: Optional[Dict[str, Any]] = None

class RiskAnalysisRequest(BaseModel):
    contract_text: str
    analysis_type: str = "comprehensive"  # comprehensive, basic, specific

class RiskAnalysisResponse(BaseModel):
    success: bool
    risks: List[Dict[str, Any]]
    risk_score: float
    recommendations: List[str]
    processing_time: float

def load_rag_system():
    """RAG ì‹œìŠ¤í…œ ë¡œë“œ"""
    global rag_system, neo4j_driver
    
    try:
        from .experiment.run_questions_v3_with_concept import load_enhanced_rag_system
        
        enhanced_lkg_retriever, hippo_retriever, llm_generator, neo4j_driver = load_enhanced_rag_system()
        
        rag_system = {
            "enhanced_lkg_retriever": enhanced_lkg_retriever,
            "hippo_retriever": hippo_retriever,
            "llm_generator": llm_generator
        }
        
        logger.info("âœ… RAG ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/", response_model=HealthResponse)
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - ì„œë²„ ìƒíƒœ í™•ì¸"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        version="1.0.0"
    )

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        version="1.0.0"
    )

@app.post("/analyze-risks", response_model=ChatResponse)
async def analyze_contract_risks(request: ChatRequest):
    """ê³„ì•½ì„œ ìœ„í—˜ì¡°í•­ ì „ìš© ë¶„ì„"""
    start_time = datetime.now()
    
    try:
        # RAG ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ë¡œë“œ ì‹œë„
        if rag_system is None:
            if not load_rag_system():
                raise HTTPException(status_code=500, detail="RAG ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # Concept í™œìš© í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        from .experiment.run_questions_v3_with_concept import concept_enhanced_hybrid_retrieve
        
        sorted_context = concept_enhanced_hybrid_retrieve(
            request.question, 
            rag_system["enhanced_lkg_retriever"], 
            rag_system["hippo_retriever"],
            rag_system["llm_generator"],
            neo4j_driver
        )
        
        if sorted_context:
            # ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
            risk_checklist = load_risk_checklist()
            
            # ìœ„í—˜ì¡°í•­ ë¶„ì„ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_instruction = (
                "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ê³„ì•½ì„œ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                "ì œê³µëœ ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì•½ì„œë¥¼ ì² ì €íˆ ë¶„ì„í•˜ì„¸ìš”.\n\n"
                "ë¶„ì„ ì‹œ ë‹¤ìŒ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”:\n"
                "1. **ë°œê²¬ëœ ìœ„í—˜ìš”ì†Œ**: ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë°œê²¬ëœ ìœ„í—˜ì¡°í•­ë“¤\n"
                "2. **ìœ„í—˜ë„ í‰ê°€**: ê° ìœ„í—˜ìš”ì†Œì˜ ìœ„í—˜ë„ (ë§¤ìš° ë†’ìŒ/ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ)\n"
                "3. **ì˜í–¥ ë‹¹ì‚¬ì**: ë§¤ìˆ˜ì¸/ë§¤ë„ì¸/ì–‘ ë‹¹ì‚¬ì\n"
                "4. **ê°œì„  ê¶Œê³ ì‚¬í•­**: êµ¬ì²´ì ì¸ ê³„ì•½ì„œ ìˆ˜ì • ì œì•ˆ\n"
                "5. **ì¢…í•© í‰ê°€**: ì „ì²´ì ì¸ ìœ„í—˜ ìˆ˜ì¤€ê³¼ ì£¼ìš” ìš°ë ¤ì‚¬í•­\n\n"
                f"=== ê³„ì•½ì„œ ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ===\n{risk_checklist}\n"
                "ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ ê³„ì•½ì„œ ë‚´ìš©ê³¼ ëŒ€ì¡°í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”."
            )
            
            messages = [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": f"ê³„ì•½ì„œ ë‚´ìš©:\n{sorted_context}\n\në¶„ì„ ìš”ì²­: {request.question}"},
            ]
            
            result = rag_system["llm_generator"].generate_response(
                messages, 
                max_new_tokens=request.max_tokens, 
                temperature=request.temperature
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… ìœ„í—˜ì¡°í•­ ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {processing_time:.2f}ì´ˆ)")
            
            return ChatResponse(
                success=True,
                answer=result,
                context_count=len(sorted_context) if isinstance(sorted_context, list) else 0,
                processing_time=processing_time
            )
        else:
            logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ChatResponse(
                success=False,
                answer="ê³„ì•½ì„œ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.",
                context_count=0,
                processing_time=(datetime.now() - start_time).total_seconds()
            )
            
    except Exception as e:
        logger.error(f"âŒ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return ChatResponse(
            success=False,
            answer=f"ìœ„í—˜ì¡°í•­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            context_count=0,
            processing_time=(datetime.now() - start_time).total_seconds()
        )

@app.post("/pipeline/run", response_model=PipelineResponse)
async def run_pipeline(request: PipelineRequest, background_tasks: BackgroundTasks):
    """ATLAS íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        background_tasks.add_task(execute_pipeline, request.start_step, request.keyword)
        
        return PipelineResponse(
            success=True,
            message="íŒŒì´í”„ë¼ì¸ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
            data={"start_step": request.start_step, "keyword": request.keyword}
        )
        
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def execute_pipeline(start_step: int, keyword: Optional[str], pipeline_id: str = None):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë°±ê·¸ë¼ìš´ë“œ)"""
    global pipeline_status
    
    if pipeline_id:
        pipeline_status[pipeline_id] = {
            "status": "running",
            "progress": 0,
            "message": "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...",
            "start_time": datetime.now().isoformat()
        }
    
    try:
        from .main_pipeline import test_atlas_pipeline
        
        if pipeline_id:
            pipeline_status[pipeline_id]["progress"] = 25
            pipeline_status[pipeline_id]["message"] = "ì§€ì‹ê·¸ë˜í”„ ì¶”ì¶œ ì¤‘..."
        
        # keywordë¥¼ ì§ì ‘ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ (í™˜ê²½ë³€ìˆ˜ ì¶©ëŒ ë°©ì§€)
        success = test_atlas_pipeline(start_step, keyword)
        
        if success:
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
            
            # íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í›„ RAG ì‹œìŠ¤í…œ ìë™ ë¡œë“œ
            logger.info("ğŸ”„ RAG ì‹œìŠ¤í…œ ìë™ ë¡œë“œ ì¤‘...")
            if check_and_load_existing_data():
                logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í›„ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
            else:
                logger.warning("âš ï¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í›„ RAG ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨")
            
            if pipeline_id:
                pipeline_status[pipeline_id] = {
                    "status": "completed",
                    "progress": 100,
                    "message": "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ",
                    "end_time": datetime.now().isoformat()
                }
        else:
            logger.error("âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")
            if pipeline_id:
                pipeline_status[pipeline_id] = {
                    "status": "failed",
                    "progress": 0,
                    "message": "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨",
                    "end_time": datetime.now().isoformat()
                }
            
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        if pipeline_id:
            pipeline_status[pipeline_id] = {
                "status": "failed",
                "progress": 0,
                "message": f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                "end_time": datetime.now().isoformat()
            }

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """ì±—ë´‡ ì§ˆë¬¸ ì²˜ë¦¬"""
    start_time = datetime.now()
    
    try:
        # RAG ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ë¡œë“œ ì‹œë„
        if rag_system is None:
            if not load_rag_system():
                raise HTTPException(status_code=500, detail="RAG ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì§ˆë¬¸ ì²˜ë¦¬ - ì§ì ‘ LLM í˜¸ì¶œë¡œ max_tokens ì œì–´
        from .experiment.run_questions_v3_with_concept import concept_enhanced_hybrid_retrieve
        
        # Concept í™œìš© í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        sorted_context = concept_enhanced_hybrid_retrieve(
            request.question, 
            rag_system["enhanced_lkg_retriever"], 
            rag_system["hippo_retriever"],
            rag_system["llm_generator"],
            neo4j_driver
        )
        
        if sorted_context:
            # ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
            risk_checklist = load_risk_checklist()
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
            system_instruction = (
                "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ê³ ê¸‰ ê³„ì•½ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¶”ì¶œëœ ì •ë³´ì™€ ì§ˆë¬¸ì„ ê¼¼ê¼¼íˆ ë¶„ì„í•˜ê³  ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. "
                "ì§€ì‹ ê·¸ë˜í”„ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ìì‹ ì˜ ì§€ì‹ì„ í™œìš©í•´ì„œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                "ë‹µë³€ì€ 'Thought: 'ë¡œ ì‹œì‘í•˜ì—¬ ì¶”ë¡  ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ê³ , "
                "'Answer: 'ë¡œ ëë‚˜ë©° ê°„ê²°í•˜ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. "
                "ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.\n\n"
                f"=== ê³„ì•½ì„œ ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ===\n{risk_checklist}\n"
                "ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ê³„ì•½ì„œì˜ ì ì¬ì  ìœ„í—˜ìš”ì†Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”."
            )
            
            messages = [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": f"{sorted_context}\n\n{request.question}"},
            ]
            
            result = rag_system["llm_generator"].generate_response(
                messages, 
                max_new_tokens=request.max_tokens, 
                temperature=request.temperature,
                validate_function=None
            )
        else:
            result = "ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return ChatResponse(
            success=True,
            answer=result if result else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            context_count=0,  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì»¨í…ìŠ¤íŠ¸ ê°œìˆ˜ ë°˜í™˜
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"ì±—ë´‡ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return ChatResponse(
            success=False,
            answer=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            context_count=0,
            processing_time=processing_time
        )

@app.get("/chat/history")
async def get_chat_history(limit: int = 10):
    """ì±—ë´‡ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    try:
        qa_file_path = "qa_history_api.json"
        
        if not os.path.exists(qa_file_path):
            return {"success": True, "history": []}
        
        with open(qa_file_path, 'r', encoding='utf-8') as f:
            qa_data = json.load(f)
        
        # ìµœê·¼ ê¸°ë¡ë§Œ ë°˜í™˜
        recent_history = qa_data[-limit:] if len(qa_data) > limit else qa_data
        
        return {"success": True, "history": recent_history}
        
    except Exception as e:
        logger.error(f"ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/chat/history")
async def clear_chat_history():
    """ì±—ë´‡ ëŒ€í™” ê¸°ë¡ ì‚­ì œ"""
    try:
        qa_file_path = "qa_history_api.json"
        
        if os.path.exists(qa_file_path):
            os.remove(qa_file_path)
        
        return {"success": True, "message": "ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
        
    except Exception as e:
        logger.error(f"ëŒ€í™” ê¸°ë¡ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
async def get_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        status = {
            "rag_system_loaded": rag_system is not None,
            "neo4j_connected": neo4j_driver is not None,
            "timestamp": datetime.now().isoformat()
        }
        
        return {"success": True, "status": status}
        
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ìƒˆë¡œìš´ ì›¹ í”Œë¡œìš° API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.post("/upload-and-run", response_model=PipelineResponse)
async def upload_and_run_pipeline(
    file: UploadFile = File(...),
    start_step: int = Form(1),
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """íŒŒì¼ ì—…ë¡œë“œì™€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ í•œ ë²ˆì— ì²˜ë¦¬"""
    try:
        # 1. íŒŒì¼ ì—…ë¡œë“œ
        file_id = str(uuid.uuid4())
        file_path = UPLOAD_DIR / f"{file_id}_{file.filename}"
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ì €ì¥
        uploaded_files[file_id] = {
            "filename": file.filename,
            "file_path": str(file_path),
            "upload_time": datetime.now().isoformat(),
            "file_size": len(content)
        }
        
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} (ID: {file_id})")
        
        # 2. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        file_info = uploaded_files[file_id]
        file_path = file_info["file_path"]
        
        # íŒŒì¼ì„ example_data ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
        example_data_dir = Path(os.getenv('DATA_DIRECTORY', 'BE/example_data'))
        example_data_dir.mkdir(exist_ok=True)
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì²˜ë¦¬
        file_ext = Path(file_path).suffix.lower()
        if file_ext == '.json':
            # JSON íŒŒì¼ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë³µì‚¬
            target_path = example_data_dir / f"contract_{file_id}.json"
            shutil.copy2(file_path, target_path)
            keyword = f"contract_{file_id}"
        elif file_ext in ['.txt', '.md']:
            # í…ìŠ¤íŠ¸/ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì¸ ê²½ìš° md_data í´ë”ì— ì €ì¥ (íŒŒì´í”„ë¼ì¸ì—ì„œ ë³€í™˜)
            if file_ext == '.md':
                # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì€ md_data í´ë”ì— ì €ì¥
                md_data_dir = example_data_dir / "md_data"
                md_data_dir.mkdir(exist_ok=True)
                target_path = md_data_dir / f"contract_{file_id}{file_ext}"
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ì€ example_dataì— ì§ì ‘ ì €ì¥
                target_path = example_data_dir / f"contract_{file_id}{file_ext}"
            
            shutil.copy2(file_path, target_path)
            keyword = f"contract_{file_id}"
        else:
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # íŒŒì´í”„ë¼ì¸ ID ìƒì„±
        pipeline_id = str(uuid.uuid4())
        
        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì´ˆê¸°í™”
        pipeline_status[pipeline_id] = {
            "status": "running",
            "start_time": datetime.now().isoformat(),
            "file_info": file_info,
            "keyword": keyword
        }
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë§ˆí¬ë‹¤ìš´ ë³€í™˜ í¬í•¨)
        actual_start_step = 0 if start_step == 1 else start_step
        background_tasks.add_task(execute_pipeline, actual_start_step, keyword, pipeline_id)
        
        logger.info(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘: {pipeline_id} (íŒŒì¼: {file.filename})")
        
        return PipelineResponse(
            success=True,
            message="íŒŒì´í”„ë¼ì¸ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
            data={
                "pipeline_id": pipeline_id,
                "keyword": keyword,
                "file_info": file_info
            }
        )
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ë° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/contract", response_model=FileUploadResponse)
async def upload_contract(file: UploadFile = File(...)):
    """ê³„ì•½ì„œ íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        # íŒŒì¼ ID ìƒì„±
        file_id = str(uuid.uuid4())
        
        # íŒŒì¼ ì €ì¥
        file_path = UPLOAD_DIR / f"{file_id}_{file.filename}"
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ì €ì¥
        uploaded_files[file_id] = {
            "filename": file.filename,
            "file_path": str(file_path),
            "upload_time": datetime.now().isoformat(),
            "file_size": len(content)
        }
        
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} (ID: {file_id})")
        
        return FileUploadResponse(
            success=True,
            file_id=file_id,
            filename=file.filename,
            message="íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/pipeline/run-with-file", response_model=PipelineResponse)
async def run_pipeline_with_file(
    file_id: str = Form(...),
    start_step: int = Form(1),
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """ì—…ë¡œë“œëœ íŒŒì¼ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    try:
        logger.info(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìš”ì²­ - file_id: {file_id}")
        logger.info(f"í˜„ì¬ uploaded_files í‚¤ë“¤: {list(uploaded_files.keys())}")
        
        if file_id not in uploaded_files:
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìš”ì²­ëœ file_id: {file_id}")
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        file_info = uploaded_files[file_id]
        file_path = file_info["file_path"]
        
        # íŒŒì¼ì„ example_data ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
        example_data_dir = Path(os.getenv('DATA_DIRECTORY', 'BE/example_data'))
        example_data_dir.mkdir(exist_ok=True)
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì²˜ë¦¬
        file_ext = Path(file_path).suffix.lower()
        if file_ext == '.json':
            # JSON íŒŒì¼ì¸ ê²½ìš° ë‚´ìš© í™•ì¸ í›„ ATLAS í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            with open(file_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            # ATLASê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if isinstance(json_data, list) and len(json_data) > 0 and 'text' in json_data[0]:
                # ì´ë¯¸ ATLAS í˜•ì‹ì¸ ê²½ìš°
                atlas_data = json_data
            elif isinstance(json_data, dict) and 'content' in json_data:
                # ì—…ë¡œë“œëœ JSONì—ì„œ content ì¶”ì¶œ
                content = json_data['content']
                atlas_data = [
                    {
                        "id": "1",
                        "text": content,
                        "metadata": {
                            "lang": "ko",
                            "filename": file_info["filename"],
                            "upload_time": file_info["upload_time"]
                        }
                    }
                ]
            else:
                # ì§ì ‘ì ì¸ JSON ë‚´ìš©ì¸ ê²½ìš°
                content = json.dumps(json_data, ensure_ascii=False, indent=2)
                atlas_data = [
                    {
                        "id": "1",
                        "text": content,
                        "metadata": {
                            "lang": "ko",
                            "filename": file_info["filename"],
                            "upload_time": file_info["upload_time"]
                        }
                    }
                ]
            
            target_path = example_data_dir / f"contract_{file_id}.json"
            with open(target_path, 'w', encoding='utf-8') as f:
                json.dump(atlas_data, f, ensure_ascii=False, indent=2)
            
            keyword = f"contract_{file_id}"
        elif file_ext in ['.txt', '.md']:
            # í…ìŠ¤íŠ¸/ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì¸ ê²½ìš° md_data í´ë”ì— ì €ì¥ (íŒŒì´í”„ë¼ì¸ì—ì„œ ë³€í™˜)
            if file_ext == '.md':
                # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì€ md_data í´ë”ì— ì €ì¥
                md_data_dir = example_data_dir / "md_data"
                md_data_dir.mkdir(exist_ok=True)
                target_path = md_data_dir / f"contract_{file_id}{file_ext}"
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ì€ example_dataì— ì§ì ‘ ì €ì¥
                target_path = example_data_dir / f"contract_{file_id}{file_ext}"
            
            shutil.copy2(file_path, target_path)
            keyword = f"contract_{file_id}"
        else:
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # íŒŒì´í”„ë¼ì¸ ID ìƒì„±
        pipeline_id = str(uuid.uuid4())
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë§ˆí¬ë‹¤ìš´ ë³€í™˜ í¬í•¨)
        actual_start_step = 0 if start_step == 1 else start_step
        background_tasks.add_task(execute_pipeline, actual_start_step, keyword, pipeline_id)
        
        return PipelineResponse(
            success=True,
            message="íŒŒì´í”„ë¼ì¸ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
            data={
                "pipeline_id": pipeline_id,
                "keyword": keyword,
                "file_info": file_info
            }
        )
        
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/pipeline/status/{pipeline_id}", response_model=PipelineStatusResponse)
async def get_pipeline_status(pipeline_id: str):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ"""
    try:
        if pipeline_id not in pipeline_status:
            raise HTTPException(status_code=404, detail="íŒŒì´í”„ë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        status_info = pipeline_status[pipeline_id]
        
        return PipelineStatusResponse(
            success=True,
            status=status_info["status"],
            progress=status_info["progress"],
            message=status_info["message"],
            data=status_info
        )
        
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analysis/risk", response_model=RiskAnalysisResponse)
async def analyze_contract_risk(request: RiskAnalysisRequest):
    """ê³„ì•½ì„œ ìœ„í—˜ ë¶„ì„"""
    start_time = datetime.now()
    
    try:
        # RAG ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ë¡œë“œ ì‹œë„
        if rag_system is None:
            if not load_rag_system():
                raise HTTPException(status_code=500, detail="RAG ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìœ„í—˜ ë¶„ì„ ìˆ˜í–‰
        risks, risk_score, recommendations = await perform_risk_analysis(
            request.contract_text, 
            request.analysis_type,
            rag_system["llm_generator"]
        )
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return RiskAnalysisResponse(
            success=True,
            risks=risks,
            risk_score=risk_score,
            recommendations=recommendations,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"âŒ ìœ„í—˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return RiskAnalysisResponse(
            success=False,
            risks=[],
            risk_score=0,
            recommendations=[],
            processing_time=(datetime.now() - start_time).total_seconds()
        )

@app.post("/analysis/auto-risk", response_model=ChatResponse)
async def auto_analyze_contract_risks(request: ChatRequest):
    """íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ëœ ê³„ì•½ì„œ ë°ì´í„° ìë™ ìœ„í—˜ì¡°í•­ ë¶„ì„"""
    start_time = datetime.now()
    
    try:
        # RAG ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ë¡œë“œ ì‹œë„
        if rag_system is None:
            if not load_rag_system():
                raise HTTPException(status_code=500, detail="RAG ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # Concept í™œìš© í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ê³„ì•½ì„œ ë°ì´í„° ì¶”ì¶œ
        from .experiment.run_questions_v3_with_concept import concept_enhanced_hybrid_retrieve
        
        # ìœ„í—˜ì¡°í•­ ë¶„ì„ì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬
        search_query = "ê³„ì•½ì„œ ì¡°í•­ ë‹¹ì‚¬ì ê±°ë˜ëŒ€ê¸ˆ ì„ í–‰ì¡°ê±´ ì§„ìˆ ë³´ì¥ ì†í•´ë°°ìƒ í•´ì œì¡°ê±´"
        sorted_context, context_ids = concept_enhanced_hybrid_retrieve(
            search_query, 
            rag_system["enhanced_lkg_retriever"], 
            rag_system["hippo_retriever"],
            rag_system["llm_generator"],
            neo4j_driver
        )
        
        if sorted_context:
            # ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
            risk_checklist = load_risk_checklist()
            
            # sorted_contextë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            context_text = '\n'.join(sorted_context) if isinstance(sorted_context, list) else str(sorted_context)
            
            # ìë™ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_instruction = (
                "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ê³„ì•½ì„œ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                "íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬ëœ ê³„ì•½ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ì¡°í•­ì„ ìë™ ë¶„ì„í•˜ì„¸ìš”.\n\n"
                "ë¶„ì„ ì‹œ ë‹¤ìŒ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”:\n"
                "## ğŸ” ë°œê²¬ëœ ìœ„í—˜ìš”ì†Œ\n"
                "### 1. ë‹¹ì‚¬ì ê´€ë ¨ ìœ„í—˜\n"
                "### 2. ê±°ë˜ëŒ€ê¸ˆ ê´€ë ¨ ìœ„í—˜\n"
                "### 3. ì„ í–‰ì¡°ê±´ ê´€ë ¨ ìœ„í—˜\n"
                "### 4. ì§„ìˆ  ë° ë³´ì¥ ê´€ë ¨ ìœ„í—˜\n"
                "### 5. ì†í•´ë°°ìƒ ê´€ë ¨ ìœ„í—˜\n"
                "### 6. ê³„ì•½ í•´ì œ ê´€ë ¨ ìœ„í—˜\n"
                "### 7. ê¸°íƒ€ ì¡°í•­ ê´€ë ¨ ìœ„í—˜\n\n"
                "ê° ìœ„í—˜ìš”ì†Œë§ˆë‹¤:\n"
                "- **ìœ„í—˜ ë‚´ìš©**: êµ¬ì²´ì ì¸ ìœ„í—˜ì¡°í•­\n"
                "- **ìœ„í—˜ë„**: ë§¤ìš° ë†’ìŒ/ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ\n"
                "- **ì˜í–¥ ë‹¹ì‚¬ì**: ë§¤ìˆ˜ì¸/ë§¤ë„ì¸/ì–‘ ë‹¹ì‚¬ì\n"
                "- **ê°œì„  ê¶Œê³ **: êµ¬ì²´ì ì¸ ìˆ˜ì • ì œì•ˆ\n\n"
                "## ğŸ“Š ì¢…í•© í‰ê°€\n"
                "- ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€\n"
                "- ì£¼ìš” ìš°ë ¤ì‚¬í•­\n"
                "- ìš°ì„ ìˆœìœ„ ê°œì„  í•­ëª©\n\n"
                f"=== ê³„ì•½ì„œ ìœ„í—˜ì¡°í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸ ===\n{risk_checklist}\n"
                "ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ ê³„ì•½ì„œ ë°ì´í„°ì™€ ëŒ€ì¡°í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”."
            )
            
            messages = [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": f"ê³„ì•½ì„œ ë°ì´í„°:\n{context_text}\n\në¶„ì„ ìš”ì²­: {request.question}"},
            ]
            
            result = rag_system["llm_generator"].generate_response(
                messages, 
                max_new_tokens=request.max_tokens, 
                temperature=request.temperature
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… ìë™ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {processing_time:.2f}ì´ˆ)")
            
            return ChatResponse(
                success=True,
                answer=result,
                context_count=len(sorted_context) if isinstance(sorted_context, list) else 0,
                processing_time=processing_time
            )
        else:
            logger.warning("âš ï¸ ê³„ì•½ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return ChatResponse(
                success=False,
                answer="ê³„ì•½ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.",
                context_count=0,
                processing_time=(datetime.now() - start_time).total_seconds()
            )
            
    except Exception as e:
        logger.error(f"âŒ ìë™ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return ChatResponse(
            success=False,
            answer=f"ìë™ ìœ„í—˜ì¡°í•­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            context_count=0,
            processing_time=(datetime.now() - start_time).total_seconds()
        )
        logger.error(f"ìœ„í—˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return RiskAnalysisResponse(
            success=False,
            risks=[],
            risk_score=0.0,
            recommendations=[],
            processing_time=processing_time
        )

async def perform_risk_analysis(contract_text: str, analysis_type: str, llm_generator):
    """ìœ„í—˜ ë¶„ì„ ìˆ˜í–‰"""
    try:
        # ìœ„í—˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        risk_analysis_prompt = f"""
ë‹¤ìŒ ê³„ì•½ì„œë¥¼ ë¶„ì„í•˜ì—¬ ìœ„í—˜ ìš”ì†Œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

ê³„ì•½ì„œ ë‚´ìš©:
{contract_text}

ë¶„ì„ ìœ í˜•: {analysis_type}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ìœ„í—˜ ìš”ì†Œ ëª©ë¡ (ìœ„í—˜ë„: ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ)
2. ê° ìœ„í—˜ ìš”ì†Œì˜ ì„¤ëª…
3. ìœ„í—˜ ì ìˆ˜ (0-100)
4. ê°œì„  ê¶Œì¥ì‚¬í•­

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "risks": [
        {{
            "type": "ìœ„í—˜ ìœ í˜•",
            "description": "ìœ„í—˜ ì„¤ëª…",
            "severity": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ",
            "clause": "ê´€ë ¨ ì¡°í•­"
        }}
    ],
    "risk_score": 75,
    "recommendations": [
        "ê¶Œì¥ì‚¬í•­ 1",
        "ê¶Œì¥ì‚¬í•­ 2"
    ]
}}
"""
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê³„ì•½ì„œ ìœ„í—˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³„ì•½ì„œì˜ ìœ„í—˜ ìš”ì†Œë¥¼ ì •í™•íˆ ë¶„ì„í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”."},
            {"role": "user", "content": risk_analysis_prompt}
        ]
        
        response = llm_generator.generate_response(
            messages, 
            max_new_tokens=8192,  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
            temperature=0.3
        )
        
        # JSON ì‘ë‹µ íŒŒì‹±
        try:
            import json
            analysis_result = json.loads(response)
            
            risks = analysis_result.get("risks", [])
            risk_score = analysis_result.get("risk_score", 0.0)
            recommendations = analysis_result.get("recommendations", [])
            
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            risks = [{"type": "ë¶„ì„ ì˜¤ë¥˜", "description": "ìœ„í—˜ ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "severity": "ì¤‘ê°„", "clause": "ì „ì²´"}]
            risk_score = 50.0
            recommendations = ["ê³„ì•½ì„œë¥¼ ë‹¤ì‹œ ê²€í† í•´ì£¼ì„¸ìš”."]
        
        return risks, risk_score, recommendations
        
    except Exception as e:
        logger.error(f"ìœ„í—˜ ë¶„ì„ ìˆ˜í–‰ ì‹¤íŒ¨: {e}")
        return [], 0.0, []

@app.get("/files")
async def list_uploaded_files():
    """ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        files = []
        for file_id, file_info in uploaded_files.items():
            files.append({
                "file_id": file_id,
                "filename": file_info["filename"],
                "upload_time": file_info["upload_time"],
                "file_size": file_info["file_size"]
            })
        
        return {"success": True, "files": files}
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/files/{file_id}")
async def delete_uploaded_file(file_id: str):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ"""
    try:
        if file_id not in uploaded_files:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        file_info = uploaded_files[file_id]
        file_path = Path(file_info["file_path"])
        
        # íŒŒì¼ ì‚­ì œ
        if file_path.exists():
            file_path.unlink()
        
        # ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
        del uploaded_files[file_id]
        
        logger.info(f"íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_info['filename']}")
        
        return {"success": True, "message": "íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    
    # ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "BE.backend_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
