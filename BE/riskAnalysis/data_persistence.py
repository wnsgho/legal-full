"""
ìœ„í—˜ ë¶„ì„ ê²°ê³¼ ì˜êµ¬ ì €ì¥ì„ ìœ„í•œ ë°ì´í„° ê´€ë¦¬ ëª¨ë“ˆ
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

class RiskAnalysisDataManager:
    """ìœ„í—˜ ë¶„ì„ ë°ì´í„° ê´€ë¦¬ì"""
    
    def __init__(self, data_dir: str = None):
        if data_dir is None:
            # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ data í´ë” ì„¤ì •
            current_dir = Path(__file__).parent
            self.data_dir = current_dir / "data"
            print(f"ğŸ” data_persistence.py ê²½ë¡œ ì„¤ì •: {self.data_dir}", flush=True)
            print(f"ğŸ” data_dir ì¡´ì¬ ì—¬ë¶€: {self.data_dir.exists()}", flush=True)
        else:
            self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        self.results_file = self.data_dir / "risk_analysis_results.json"
        self.metadata_file = self.data_dir / "analysis_metadata.json"
        print(f"ğŸ” results_file ê²½ë¡œ: {self.results_file}", flush=True)
        print(f"ğŸ” results_file ì¡´ì¬ ì—¬ë¶€: {self.results_file.exists()}", flush=True)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        self.data_dir = self.data_dir.resolve()
        self.results_file = self.results_file.resolve()
        self.metadata_file = self.metadata_file.resolve()
        print(f"ğŸ” ì ˆëŒ€ ê²½ë¡œ results_file: {self.results_file}", flush=True)
        print(f"ğŸ” ì ˆëŒ€ ê²½ë¡œ results_file ì¡´ì¬ ì—¬ë¶€: {self.results_file.exists()}", flush=True)
    
    def save_analysis_result(self, analysis_id: str, result: Dict[str, Any]) -> bool:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing_data = self.load_all_results()
            
            # ìƒˆ ê²°ê³¼ ì¶”ê°€
            existing_data[analysis_id] = result
            
            # íŒŒì¼ì— ì €ì¥
            with open(self.results_file, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            self._update_metadata(analysis_id, result)
            
            return True
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_analysis_result(self, analysis_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
        try:
            all_results = self.load_all_results()
            return all_results.get(analysis_id)
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def load_all_results(self) -> Dict[str, Any]:
        """ëª¨ë“  ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
        try:
            print(f"ğŸ” load_all_results ì‹œì‘ - results_file: {self.results_file}", flush=True)
            print(f"ğŸ” results_file ì¡´ì¬ ì—¬ë¶€: {self.results_file.exists()}", flush=True)
            
            if not self.results_file.exists():
                print(f"ğŸ” results_fileì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ", flush=True)
                return {}
            
            with open(self.results_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"ğŸ” ë¡œë“œëœ ë°ì´í„° ê°œìˆ˜: {len(data)}", flush=True)
                return data
        except Exception as e:
            print(f"âŒ ëª¨ë“  ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)
            return {}
    
    def delete_analysis_result(self, analysis_id: str) -> bool:
        """ë¶„ì„ ê²°ê³¼ ì‚­ì œ"""
        try:
            all_results = self.load_all_results()
            if analysis_id in all_results:
                del all_results[analysis_id]
                
                with open(self.results_file, 'w', encoding='utf-8') as f:
                    json.dump(all_results, f, ensure_ascii=False, indent=2)
                
                self._update_metadata(analysis_id, None, delete=True)
                return True
            return False
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def get_analysis_list(self, limit: int = 50) -> List[Dict[str, Any]]:
        """ë¶„ì„ ëª©ë¡ ì¡°íšŒ (ìµœì‹ ìˆœ)"""
        try:
            all_results = self.load_all_results()
            results_list = list(all_results.values())
            
            # ìƒì„±ì¼ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
            results_list.sort(
                key=lambda x: x.get('created_at', ''), 
                reverse=True
            )
            
            return results_list[:limit]
        except Exception as e:
            print(f"âŒ ë¶„ì„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def search_analysis_results(self, query: str) -> List[Dict[str, Any]]:
        """ë¶„ì„ ê²°ê³¼ ê²€ìƒ‰"""
        try:
            all_results = self.load_all_results()
            matching_results = []
            
            query_lower = query.lower()
            
            for result in all_results.values():
                # ê³„ì•½ì„œëª…ìœ¼ë¡œ ê²€ìƒ‰
                if query_lower in result.get('contract_name', '').lower():
                    matching_results.append(result)
                    continue
                
                # ë¶„ì„ ê²°ê³¼ ë‚´ìš©ìœ¼ë¡œ ê²€ìƒ‰
                analysis_result = result.get('analysis_result', {})
                if query_lower in str(analysis_result).lower():
                    matching_results.append(result)
                    continue
            
            return matching_results
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _update_metadata(self, analysis_id: str, result: Optional[Dict[str, Any]], delete: bool = False):
        """ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸"""
        try:
            # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            metadata = {}
            if self.metadata_file.exists():
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            
            if delete:
                # ì‚­ì œëœ ê²½ìš° ë©”íƒ€ë°ì´í„°ì—ì„œ ì œê±°
                if analysis_id in metadata:
                    del metadata[analysis_id]
            else:
                # ìƒˆ ê²°ê³¼ì˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                metadata[analysis_id] = {
                    "analysis_id": analysis_id,
                    "contract_name": result.get('contract_name', ''),
                    "created_at": result.get('created_at', ''),
                    "analysis_type": result.get('analysis_type', ''),
                    "overall_risk_score": result.get('analysis_result', {}).get('overall_risk_score', 0),
                    "total_parts": len(result.get('analysis_result', {}).get('part_results', [])),
                    "file_size": len(str(result))
                }
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"âŒ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """ë¶„ì„ í†µê³„ ì¡°íšŒ"""
        try:
            all_results = self.load_all_results()
            
            if not all_results:
                return {
                    "total_analyses": 0,
                    "average_risk_score": 0,
                    "high_risk_analyses": 0,
                    "analysis_types": {}
                }
            
            total_analyses = len(all_results)
            risk_scores = []
            high_risk_count = 0
            analysis_types = {}
            
            for result in all_results.values():
                # ìœ„í—˜ë„ ì ìˆ˜ ìˆ˜ì§‘
                overall_risk_score = result.get('analysis_result', {}).get('overall_risk_score', 0)
                risk_scores.append(overall_risk_score)
                
                if overall_risk_score >= 3.0:
                    high_risk_count += 1
                
                # ë¶„ì„ ìœ í˜•ë³„ í†µê³„
                analysis_type = result.get('analysis_type', 'unknown')
                analysis_types[analysis_type] = analysis_types.get(analysis_type, 0) + 1
            
            return {
                "total_analyses": total_analyses,
                "average_risk_score": sum(risk_scores) / len(risk_scores) if risk_scores else 0,
                "high_risk_analyses": high_risk_count,
                "analysis_types": analysis_types
            }
        except Exception as e:
            print(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def cleanup_old_results(self, days: int = 30) -> int:
        """ì˜¤ë˜ëœ ë¶„ì„ ê²°ê³¼ ì •ë¦¬"""
        try:
            from datetime import datetime, timedelta
            
            cutoff_date = datetime.now() - timedelta(days=days)
            all_results = self.load_all_results()
            deleted_count = 0
            
            results_to_delete = []
            
            for analysis_id, result in all_results.items():
                created_at_str = result.get('created_at', '')
                if created_at_str:
                    try:
                        created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
                        if created_at < cutoff_date:
                            results_to_delete.append(analysis_id)
                    except:
                        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
                        continue
            
            # ì˜¤ë˜ëœ ê²°ê³¼ ì‚­ì œ
            for analysis_id in results_to_delete:
                if self.delete_analysis_result(analysis_id):
                    deleted_count += 1
            
            return deleted_count
        except Exception as e:
            print(f"âŒ ì˜¤ë˜ëœ ê²°ê³¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0

# ì „ì—­ ë°ì´í„° ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
data_manager = RiskAnalysisDataManager()
